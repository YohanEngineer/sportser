[2023-04-02 16:17:11,853] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:17:11,867] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:17:11,871] ERROR Stopping due to error (org.apache.kafka.connect.cli.ConnectStandalone:130)
java.nio.file.NoSuchFileException: config/connect-standalone.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:682)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:669)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:75)
[2023-04-02 16:18:07,461] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:18:07,477] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:18:07,480] ERROR Stopping due to error (org.apache.kafka.connect.cli.ConnectStandalone:130)
java.nio.file.NoSuchFileException: config/connect-standalone.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:682)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:669)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:75)
[2023-04-02 16:19:28,113] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:19:28,129] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:19:28,134] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2023-04-02 16:19:30,145] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-04-02 16:19:30,146] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,146] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,147] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,148] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,148] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,148] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,148] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,148] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,149] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,149] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,149] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,150] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,151] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,151] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,152] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,153] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,153] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,153] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,153] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,153] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,154] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,155] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,155] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,155] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:19:30,158] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,159] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,159] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,159] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,159] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,160] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,160] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,160] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,160] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,161] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,161] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,161] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,161] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,162] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,162] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,162] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,163] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,163] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,164] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,164] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,164] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,164] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,164] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,165] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,165] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,165] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,165] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,168] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,169] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,169] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,169] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,169] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:19:30,170] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,171] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,171] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:19:30,201] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2023-04-02 16:19:30,202] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:379)
[2023-04-02 16:19:30,202] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:325)
[2023-04-02 16:19:30,205] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2023-04-02 16:19:30,282] WARN These configurations '[offset.flush.interval.ms, key.converter.schemas.enable, offset.storage.file.filename, value.converter.schemas.enable, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:385)
[2023-04-02 16:19:30,282] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:19:30,282] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:19:30,282] INFO Kafka startTimeMs: 1680445170282 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:19:30,730] INFO Kafka cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.connect.runtime.WorkerConfig:342)
[2023-04-02 16:19:30,735] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:19:30,742] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:19:30,742] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:19:30,742] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:19:30,759] INFO Logging initialized @3262ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-04-02 16:19:30,830] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2023-04-02 16:19:30,831] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2023-04-02 16:19:30,877] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_292-b10 (org.eclipse.jetty.server.Server:375)
[2023-04-02 16:19:30,914] INFO Started http_8083@741b3bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-04-02 16:19:30,915] INFO Started @3419ms (org.eclipse.jetty.server.Server:415)
[2023-04-02 16:19:30,936] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:19:30,936] INFO REST server listening at http://192.168.1.245:8083/, advertising URL http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2023-04-02 16:19:30,936] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:19:30,936] INFO REST admin endpoints at http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:213)
[2023-04-02 16:19:30,937] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:19:30,938] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-04-02 16:19:30,947] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:19:30,947] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:19:30,947] INFO Kafka startTimeMs: 1680445170947 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:19:31,021] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:19:31,022] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:19:31,028] INFO Kafka Connect standalone worker initialization took 2911ms (org.apache.kafka.connect.cli.ConnectStandalone:103)
[2023-04-02 16:19:31,028] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2023-04-02 16:19:31,029] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2023-04-02 16:19:31,029] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:202)
[2023-04-02 16:19:31,029] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2023-04-02 16:19:31,032] INFO Worker started (org.apache.kafka.connect.runtime.Worker:212)
[2023-04-02 16:19:31,032] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2023-04-02 16:19:31,032] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:217)
[2023-04-02 16:19:31,080] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:236)
[2023-04-02 16:19:31,112] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-04-02 16:19:31,112] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-04-02 16:19:31,113] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2023-04-02 16:19:31,802] INFO Started o.e.j.s.ServletContextHandler@341a8659{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-04-02 16:19:31,802] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:309)
[2023-04-02 16:19:31,802] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2023-04-02 16:19:31,809] ERROR Failed to create job for ../config/mongodb-sink.properties (org.apache.kafka.connect.cli.ConnectStandalone:111)
[2023-04-02 16:19:31,810] ERROR Stopping after connector error (org.apache.kafka.connect.cli.ConnectStandalone:121)
java.util.concurrent.ExecutionException: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches org.mongodb.kafka.connect.MongoSinkConnector, available connectors are: PluginDesc{klass=class com.mongodb.kafka.connect.MongoSinkConnector, name='com.mongodb.kafka.connect.MongoSinkConnector', version='1.10.0', encodedVersion=1.10.0, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class com.mongodb.kafka.connect.MongoSourceConnector, name='com.mongodb.kafka.connect.MongoSourceConnector', version='1.10.0', encodedVersion=1.10.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='3.4.0', encodedVersion=3.4.0, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='3.4.0', encodedVersion=3.4.0, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.util.ConvertingFutureCallback.result(ConvertingFutureCallback.java:115)
	at org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:99)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:118)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches org.mongodb.kafka.connect.MongoSinkConnector, available connectors are: PluginDesc{klass=class com.mongodb.kafka.connect.MongoSinkConnector, name='com.mongodb.kafka.connect.MongoSinkConnector', version='1.10.0', encodedVersion=1.10.0, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class com.mongodb.kafka.connect.MongoSourceConnector, name='com.mongodb.kafka.connect.MongoSourceConnector', version='1.10.0', encodedVersion=1.10.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='3.4.0', encodedVersion=3.4.0, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='3.4.0', encodedVersion=3.4.0, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='3.4.0', encodedVersion=3.4.0, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:249)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:220)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:689)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:689)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:457)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:377)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2023-04-02 16:19:31,812] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2023-04-02 16:19:31,812] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:317)
[2023-04-02 16:19:31,819] INFO Stopped http_8083@741b3bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-04-02 16:19:31,819] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-04-02 16:19:31,821] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:334)
[2023-04-02 16:19:31,821] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:106)
[2023-04-02 16:19:31,822] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:219)
[2023-04-02 16:19:31,822] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2023-04-02 16:19:31,822] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:19:31,822] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:19:31,823] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:19:31,825] INFO App info kafka.connect for 192.168.1.245:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:19:31,826] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:240)
[2023-04-02 16:19:31,826] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:124)
[2023-04-02 16:19:31,826] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2023-04-02 16:21:05,056] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:21:05,071] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:21:05,077] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2023-04-02 16:21:07,168] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-04-02 16:21:07,169] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,170] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,170] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,171] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,171] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,171] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,171] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,171] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,172] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,172] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,172] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,173] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,174] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,175] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,176] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,177] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:21:07,181] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,181] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,181] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,181] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,182] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,183] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,183] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,183] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,183] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,183] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,184] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,184] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,184] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,184] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,185] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,185] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,185] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,185] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,185] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,187] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,187] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,190] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,192] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,192] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:21:07,193] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,193] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,193] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:21:07,223] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2023-04-02 16:21:07,224] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:379)
[2023-04-02 16:21:07,224] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:325)
[2023-04-02 16:21:07,228] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2023-04-02 16:21:07,328] WARN These configurations '[offset.flush.interval.ms, key.converter.schemas.enable, offset.storage.file.filename, value.converter.schemas.enable, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:385)
[2023-04-02 16:21:07,329] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:21:07,329] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:21:07,329] INFO Kafka startTimeMs: 1680445267329 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:21:07,713] INFO Kafka cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.connect.runtime.WorkerConfig:342)
[2023-04-02 16:21:07,718] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:21:07,727] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:21:07,727] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:21:07,727] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:21:07,741] INFO Logging initialized @3306ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-04-02 16:21:07,819] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2023-04-02 16:21:07,819] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2023-04-02 16:21:07,864] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_292-b10 (org.eclipse.jetty.server.Server:375)
[2023-04-02 16:21:07,898] INFO Started http_8083@2ed3b1f5{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-04-02 16:21:07,899] INFO Started @3463ms (org.eclipse.jetty.server.Server:415)
[2023-04-02 16:21:07,921] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:21:07,921] INFO REST server listening at http://192.168.1.245:8083/, advertising URL http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2023-04-02 16:21:07,922] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:21:07,922] INFO REST admin endpoints at http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:213)
[2023-04-02 16:21:07,922] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:21:07,924] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-04-02 16:21:07,932] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:21:07,933] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:21:07,933] INFO Kafka startTimeMs: 1680445267932 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:21:08,006] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:21:08,008] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:21:08,014] INFO Kafka Connect standalone worker initialization took 2951ms (org.apache.kafka.connect.cli.ConnectStandalone:103)
[2023-04-02 16:21:08,014] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2023-04-02 16:21:08,014] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2023-04-02 16:21:08,015] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:202)
[2023-04-02 16:21:08,015] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2023-04-02 16:21:08,017] INFO Worker started (org.apache.kafka.connect.runtime.Worker:212)
[2023-04-02 16:21:08,018] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2023-04-02 16:21:08,018] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:217)
[2023-04-02 16:21:08,067] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:236)
[2023-04-02 16:21:08,103] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-04-02 16:21:08,103] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-04-02 16:21:08,104] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2023-04-02 16:21:08,841] INFO Started o.e.j.s.ServletContextHandler@181d7f28{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-04-02 16:21:08,842] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:309)
[2023-04-02 16:21:08,842] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2023-04-02 16:21:08,909] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:08,913] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:08,915] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:08,937] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:08,944] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:08,948] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:09,051] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@243b6fd]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@fe81762]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:21:09,078] INFO Opened connection [connectionId{localValue:2, serverValue:734}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:21:09,080] INFO Opened connection [connectionId{localValue:1, serverValue:733}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:21:09,081] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=47556833} (org.mongodb.driver.cluster:71)
[2023-04-02 16:21:09,114] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-04-02 16:21:09,138] INFO [mongodb-sink-connector|worker] Creating connector mongodb-sink-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:293)
[2023-04-02 16:21:09,142] INFO [mongodb-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:21:09,142] INFO [mongodb-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:21:09,148] INFO [mongodb-sink-connector|worker] Instantiated connector mongodb-sink-connector with version 1.10.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:315)
[2023-04-02 16:21:09,148] INFO [mongodb-sink-connector|worker] Finished creating connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:336)
[2023-04-02 16:21:09,152] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:21:09,153] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:21:09,156] INFO [mongodb-sink-connector|task-0] Creating task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:596)
[2023-04-02 16:21:09,163] INFO [mongodb-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2023-04-02 16:21:09,163] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:21:09,165] INFO [mongodb-sink-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2023-04-02 16:21:09,166] INFO [mongodb-sink-connector|task-0] Instantiated task mongodb-sink-connector-0 with version 1.10.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:610)
[2023-04-02 16:21:09,168] INFO [mongodb-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:21:09,168] INFO [mongodb-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:623)
[2023-04-02 16:21:09,168] INFO [mongodb-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:21:09,168] INFO [mongodb-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:629)
[2023-04-02 16:21:09,168] INFO [mongodb-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:636)
[2023-04-02 16:21:09,179] INFO [mongodb-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1257)
[2023-04-02 16:21:09,182] INFO [mongodb-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:21:09,182] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:21:09,194] INFO [mongodb-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongodb-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongodb-sink-connector
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2023-04-02 16:21:09,250] WARN [mongodb-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:385)
[2023-04-02 16:21:09,251] INFO [mongodb-sink-connector|task-0] Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:21:09,251] INFO [mongodb-sink-connector|task-0] Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:21:09,251] INFO [mongodb-sink-connector|task-0] Kafka startTimeMs: 1680445269251 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:21:09,264] INFO Created connector mongodb-sink-connector (org.apache.kafka.connect.cli.ConnectStandalone:113)
[2023-04-02 16:21:09,267] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Subscribed to topic(s): emergency-data-collector, hr-data-collector, notification-channel (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2023-04-02 16:21:09,267] INFO [mongodb-sink-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:65)
[2023-04-02 16:21:09,272] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:09,273] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:09,276] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:21:09,282] INFO [mongodb-sink-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.10.0"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@243b6fd]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:21:09,286] INFO [mongodb-sink-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:130)
[2023-04-02 16:21:09,297] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:3, serverValue:735}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:21:09,304] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15228917} (org.mongodb.driver.cluster:71)
[2023-04-02 16:21:09,307] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:316)
[2023-04-02 16:21:09,307] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:4, serverValue:736}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:21:09,308] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:201)
[2023-04-02 16:21:09,481] WARN [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Error while fetching metadata with correlation id 2 : {notification-channel=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1105)
[2023-04-02 16:21:09,484] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition emergency-data-collector-0 to 0 since the associated topicId changed from null to Yg93KKfEREu7IYKtwwu5Vg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:21:09,485] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition hr-data-collector-0 to 0 since the associated topicId changed from null to Un46eKRYRXK2oaNAf1sTKg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:21:09,487] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.clients.Metadata:287)
[2023-04-02 16:21:09,489] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator m1-yohan:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:896)
[2023-04-02 16:21:09,493] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:21:09,569] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-45aca207-acff-4299-a684-cd2321611857 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:21:09,572] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:21:09,572] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:21:09,609] WARN [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Error while fetching metadata with correlation id 7 : {notification-channel=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1105)
[2023-04-02 16:21:09,612] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mongodb-sink-connector-0-45aca207-acff-4299-a684-cd2321611857', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:627)
[2023-04-02 16:21:09,714] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition notification-channel-0 to 0 since the associated topicId changed from null to aNC6h-jiR52lEVqVKTD2Ug (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:21:09,718] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Finished assignment for group at generation 1: {connector-consumer-mongodb-sink-connector-0-45aca207-acff-4299-a684-cd2321611857=Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:710)
[2023-04-02 16:21:09,750] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mongodb-sink-connector-0-45aca207-acff-4299-a684-cd2321611857', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:802)
[2023-04-02 16:21:09,752] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Notifying assignor about the new Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:305)
[2023-04-02 16:21:09,753] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Adding newly assigned partitions: emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:317)
[2023-04-02 16:21:09,766] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:21:09,769] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition emergency-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:21:09,769] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition hr-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:21:09,847] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition notification-channel-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:21:09,848] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition emergency-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:21:09,848] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition hr-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:21:09,950] ERROR [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:210)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:230)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:156)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:518)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:495)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:335)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:237)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:206)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:177)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.DataException: JsonConverter with schemas.enable requires "schema" and "payload" fields and may not contain additional fields. If you are trying to deserialize plain JSON data, set schemas.enable=false in your converter configuration.
	at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:330)
	at org.apache.kafka.connect.storage.Converter.toConnectData(Converter.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$4(WorkerSinkTask.java:518)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:180)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:214)
	... 14 more
[2023-04-02 16:21:09,953] INFO [mongodb-sink-connector|task-0] Stopping MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:116)
[2023-04-02 16:21:09,956] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Revoke previously assigned partitions emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:336)
[2023-04-02 16:21:09,958] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Member connector-consumer-mongodb-sink-connector-0-45aca207-acff-4299-a684-cd2321611857 sending LeaveGroup request to coordinator m1-yohan:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1123)
[2023-04-02 16:21:09,961] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1015)
[2023-04-02 16:21:09,962] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:21:09,975] INFO [mongodb-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:21:09,976] INFO [mongodb-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:21:09,976] INFO [mongodb-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:21:09,980] INFO [mongodb-sink-connector|task-0] App info kafka.consumer for connector-consumer-mongodb-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:23:51,814] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2023-04-02 16:23:51,828] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:317)
[2023-04-02 16:23:51,887] INFO Stopped http_8083@2ed3b1f5{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-04-02 16:23:51,890] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-04-02 16:23:51,905] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:334)
[2023-04-02 16:23:51,907] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:106)
[2023-04-02 16:23:51,911] INFO [mongodb-sink-connector|task-0] Stopping task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:998)
[2023-04-02 16:23:51,936] INFO [mongodb-sink-connector|worker] Stopping connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:404)
[2023-04-02 16:23:51,937] INFO [mongodb-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:254)
[2023-04-02 16:23:51,938] INFO [mongodb-sink-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:274)
[2023-04-02 16:23:51,945] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:219)
[2023-04-02 16:23:51,954] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2023-04-02 16:23:51,954] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:23:51,954] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:23:51,954] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:23:51,956] INFO App info kafka.connect for 192.168.1.245:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:23:51,956] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:240)
[2023-04-02 16:23:51,959] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:124)
[2023-04-02 16:23:51,959] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2023-04-02 16:23:55,227] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:23:55,244] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:23:55,250] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2023-04-02 16:23:57,317] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-04-02 16:23:57,318] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,318] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,319] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,319] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,320] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,320] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,320] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,320] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,321] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,322] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,323] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,324] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,325] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,326] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,326] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,326] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,326] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,326] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:23:57,327] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,327] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,328] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,328] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,328] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,328] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,329] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,330] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,331] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,331] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,331] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,331] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,331] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,333] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,334] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,334] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,335] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,336] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:23:57,336] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,337] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,337] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:23:57,369] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2023-04-02 16:23:57,369] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:379)
[2023-04-02 16:23:57,370] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:325)
[2023-04-02 16:23:57,373] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2023-04-02 16:23:57,462] WARN These configurations '[offset.flush.interval.ms, key.converter.schemas.enable, offset.storage.file.filename, value.converter.schemas.enable, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:385)
[2023-04-02 16:23:57,462] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:23:57,462] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:23:57,462] INFO Kafka startTimeMs: 1680445437462 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:23:57,821] INFO Kafka cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.connect.runtime.WorkerConfig:342)
[2023-04-02 16:23:57,826] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:23:57,835] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:23:57,835] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:23:57,836] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:23:57,852] INFO Logging initialized @3330ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-04-02 16:23:57,927] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2023-04-02 16:23:57,927] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2023-04-02 16:23:57,979] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_292-b10 (org.eclipse.jetty.server.Server:375)
[2023-04-02 16:23:58,028] INFO Started http_8083@2ed3b1f5{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-04-02 16:23:58,029] INFO Started @3509ms (org.eclipse.jetty.server.Server:415)
[2023-04-02 16:23:58,061] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:23:58,062] INFO REST server listening at http://192.168.1.245:8083/, advertising URL http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2023-04-02 16:23:58,062] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:23:58,062] INFO REST admin endpoints at http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:213)
[2023-04-02 16:23:58,062] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:23:58,064] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-04-02 16:23:58,074] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:23:58,075] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:23:58,075] INFO Kafka startTimeMs: 1680445438074 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:23:58,154] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:23:58,155] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:23:58,160] INFO Kafka Connect standalone worker initialization took 2929ms (org.apache.kafka.connect.cli.ConnectStandalone:103)
[2023-04-02 16:23:58,161] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2023-04-02 16:23:58,161] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2023-04-02 16:23:58,161] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:202)
[2023-04-02 16:23:58,162] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2023-04-02 16:23:58,164] INFO Worker started (org.apache.kafka.connect.runtime.Worker:212)
[2023-04-02 16:23:58,164] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2023-04-02 16:23:58,164] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:217)
[2023-04-02 16:23:58,213] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:236)
[2023-04-02 16:23:58,248] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-04-02 16:23:58,248] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-04-02 16:23:58,249] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2023-04-02 16:23:58,896] INFO Started o.e.j.s.ServletContextHandler@181d7f28{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-04-02 16:23:58,897] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:309)
[2023-04-02 16:23:58,897] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2023-04-02 16:23:58,970] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:58,976] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:58,978] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:58,986] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:58,987] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:58,990] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:59,067] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@77f66a82]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@1d091a5]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:23:59,089] INFO Opened connection [connectionId{localValue:1, serverValue:741}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:23:59,089] INFO Opened connection [connectionId{localValue:2, serverValue:740}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:23:59,090] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=23975709} (org.mongodb.driver.cluster:71)
[2023-04-02 16:23:59,101] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-04-02 16:23:59,114] INFO [mongodb-sink-connector|worker] Creating connector mongodb-sink-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:293)
[2023-04-02 16:23:59,116] INFO [mongodb-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:23:59,116] INFO [mongodb-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:23:59,121] INFO [mongodb-sink-connector|worker] Instantiated connector mongodb-sink-connector with version 1.10.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:315)
[2023-04-02 16:23:59,121] INFO [mongodb-sink-connector|worker] Finished creating connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:336)
[2023-04-02 16:23:59,125] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:23:59,126] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:23:59,128] INFO [mongodb-sink-connector|task-0] Creating task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:596)
[2023-04-02 16:23:59,133] INFO [mongodb-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2023-04-02 16:23:59,134] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:23:59,135] INFO [mongodb-sink-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2023-04-02 16:23:59,135] INFO [mongodb-sink-connector|task-0] Instantiated task mongodb-sink-connector-0 with version 1.10.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:610)
[2023-04-02 16:23:59,136] INFO [mongodb-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:23:59,136] INFO [mongodb-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:623)
[2023-04-02 16:23:59,136] INFO [mongodb-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:23:59,136] INFO [mongodb-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:629)
[2023-04-02 16:23:59,137] INFO [mongodb-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:636)
[2023-04-02 16:23:59,141] INFO [mongodb-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1257)
[2023-04-02 16:23:59,142] INFO [mongodb-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:23:59,143] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:23:59,148] INFO [mongodb-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongodb-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongodb-sink-connector
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2023-04-02 16:23:59,189] WARN [mongodb-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:385)
[2023-04-02 16:23:59,189] INFO [mongodb-sink-connector|task-0] Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:23:59,189] INFO [mongodb-sink-connector|task-0] Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:23:59,189] INFO [mongodb-sink-connector|task-0] Kafka startTimeMs: 1680445439189 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:23:59,200] INFO Created connector mongodb-sink-connector (org.apache.kafka.connect.cli.ConnectStandalone:113)
[2023-04-02 16:23:59,201] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Subscribed to topic(s): emergency-data-collector, hr-data-collector, notification-channel (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2023-04-02 16:23:59,202] INFO [mongodb-sink-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:65)
[2023-04-02 16:23:59,205] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:59,207] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:59,209] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:23:59,213] INFO [mongodb-sink-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.10.0"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@77f66a82]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:23:59,216] INFO [mongodb-sink-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:130)
[2023-04-02 16:23:59,224] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:4, serverValue:742}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:23:59,229] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:3, serverValue:743}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:23:59,230] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15379166} (org.mongodb.driver.cluster:71)
[2023-04-02 16:23:59,234] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:316)
[2023-04-02 16:23:59,235] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:201)
[2023-04-02 16:23:59,285] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition notification-channel-0 to 0 since the associated topicId changed from null to aNC6h-jiR52lEVqVKTD2Ug (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:23:59,286] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition emergency-data-collector-0 to 0 since the associated topicId changed from null to Yg93KKfEREu7IYKtwwu5Vg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:23:59,286] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition hr-data-collector-0 to 0 since the associated topicId changed from null to Un46eKRYRXK2oaNAf1sTKg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:23:59,290] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.clients.Metadata:287)
[2023-04-02 16:23:59,293] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator m1-yohan:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:896)
[2023-04-02 16:23:59,296] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:23:59,350] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-56787572-6e9d-47fd-8553-b6ff91392bb0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:23:59,352] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:23:59,352] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:23:59,367] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-mongodb-sink-connector-0-56787572-6e9d-47fd-8553-b6ff91392bb0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:627)
[2023-04-02 16:23:59,369] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Finished assignment for group at generation 3: {connector-consumer-mongodb-sink-connector-0-56787572-6e9d-47fd-8553-b6ff91392bb0=Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:710)
[2023-04-02 16:23:59,389] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-mongodb-sink-connector-0-56787572-6e9d-47fd-8553-b6ff91392bb0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:802)
[2023-04-02 16:23:59,392] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Notifying assignor about the new Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:305)
[2023-04-02 16:23:59,401] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Adding newly assigned partitions: emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:317)
[2023-04-02 16:23:59,439] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:23:59,441] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition emergency-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:23:59,441] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition hr-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:23:59,478] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition notification-channel-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:23:59,479] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition emergency-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:23:59,479] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition hr-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:23:59,546] ERROR [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:210)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:230)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:156)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:518)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:495)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:335)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:237)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:206)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:177)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.DataException: JsonConverter with schemas.enable requires "schema" and "payload" fields and may not contain additional fields. If you are trying to deserialize plain JSON data, set schemas.enable=false in your converter configuration.
	at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:330)
	at org.apache.kafka.connect.storage.Converter.toConnectData(Converter.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$4(WorkerSinkTask.java:518)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:180)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:214)
	... 14 more
[2023-04-02 16:23:59,549] INFO [mongodb-sink-connector|task-0] Stopping MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:116)
[2023-04-02 16:23:59,552] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Revoke previously assigned partitions emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:336)
[2023-04-02 16:23:59,554] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Member connector-consumer-mongodb-sink-connector-0-56787572-6e9d-47fd-8553-b6ff91392bb0 sending LeaveGroup request to coordinator m1-yohan:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1123)
[2023-04-02 16:23:59,556] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1015)
[2023-04-02 16:23:59,556] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:23:59,560] INFO [mongodb-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:23:59,560] INFO [mongodb-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:23:59,560] INFO [mongodb-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:23:59,566] INFO [mongodb-sink-connector|task-0] App info kafka.consumer for connector-consumer-mongodb-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:26:57,813] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2023-04-02 16:26:57,827] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:317)
[2023-04-02 16:26:57,856] INFO Stopped http_8083@2ed3b1f5{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-04-02 16:26:57,857] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-04-02 16:26:57,861] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:334)
[2023-04-02 16:26:57,862] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:106)
[2023-04-02 16:26:57,867] INFO [mongodb-sink-connector|task-0] Stopping task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:998)
[2023-04-02 16:26:57,884] INFO [mongodb-sink-connector|worker] Stopping connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:404)
[2023-04-02 16:26:57,884] INFO [mongodb-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:254)
[2023-04-02 16:26:57,885] INFO [mongodb-sink-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:274)
[2023-04-02 16:26:57,886] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:219)
[2023-04-02 16:26:57,893] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2023-04-02 16:26:57,894] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:26:57,895] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:26:57,895] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:26:57,896] INFO App info kafka.connect for 192.168.1.245:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:26:57,896] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:240)
[2023-04-02 16:26:57,898] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:124)
[2023-04-02 16:26:57,898] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2023-04-02 16:27:00,799] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:27:00,814] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:27:00,820] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2023-04-02 16:27:02,904] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-04-02 16:27:02,905] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,906] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,906] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,907] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,908] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,908] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,908] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,908] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,908] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,908] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,909] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,910] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,911] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,912] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,913] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,913] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,913] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,913] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:27:02,915] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,915] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,915] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,915] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,915] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,915] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,916] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,917] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,918] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,919] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,919] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,920] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,921] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,922] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,923] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,923] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:27:02,924] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,924] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,925] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:27:02,953] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2023-04-02 16:27:02,953] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:379)
[2023-04-02 16:27:02,954] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:325)
[2023-04-02 16:27:02,957] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2023-04-02 16:27:03,052] WARN These configurations '[offset.flush.interval.ms, key.converter.schemas.enable, offset.storage.file.filename, value.converter.schemas.enable, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:385)
[2023-04-02 16:27:03,052] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:27:03,052] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:27:03,053] INFO Kafka startTimeMs: 1680445623052 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:27:03,403] INFO Kafka cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.connect.runtime.WorkerConfig:342)
[2023-04-02 16:27:03,408] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:27:03,416] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:27:03,416] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:27:03,416] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:27:03,430] INFO Logging initialized @3295ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-04-02 16:27:03,513] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2023-04-02 16:27:03,513] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2023-04-02 16:27:03,561] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_292-b10 (org.eclipse.jetty.server.Server:375)
[2023-04-02 16:27:03,593] INFO Started http_8083@741b3bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-04-02 16:27:03,594] INFO Started @3459ms (org.eclipse.jetty.server.Server:415)
[2023-04-02 16:27:03,615] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:27:03,615] INFO REST server listening at http://192.168.1.245:8083/, advertising URL http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2023-04-02 16:27:03,615] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:27:03,616] INFO REST admin endpoints at http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:213)
[2023-04-02 16:27:03,616] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:27:03,618] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-04-02 16:27:03,627] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:27:03,628] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:27:03,628] INFO Kafka startTimeMs: 1680445623627 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:27:03,705] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:27:03,706] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:27:03,711] INFO Kafka Connect standalone worker initialization took 2909ms (org.apache.kafka.connect.cli.ConnectStandalone:103)
[2023-04-02 16:27:03,711] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2023-04-02 16:27:03,711] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2023-04-02 16:27:03,712] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:202)
[2023-04-02 16:27:03,712] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2023-04-02 16:27:03,714] INFO Worker started (org.apache.kafka.connect.runtime.Worker:212)
[2023-04-02 16:27:03,714] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2023-04-02 16:27:03,714] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:217)
[2023-04-02 16:27:03,763] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:236)
[2023-04-02 16:27:03,795] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-04-02 16:27:03,796] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-04-02 16:27:03,797] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2023-04-02 16:27:04,505] INFO Started o.e.j.s.ServletContextHandler@4943defe{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-04-02 16:27:04,506] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:309)
[2023-04-02 16:27:04,506] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2023-04-02 16:27:04,574] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,582] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,585] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,593] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,595] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,596] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,686] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@58038260]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@77fa5128]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:27:04,717] INFO Opened connection [connectionId{localValue:2, serverValue:744}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:27:04,717] INFO Opened connection [connectionId{localValue:1, serverValue:745}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:27:04,718] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=44529875} (org.mongodb.driver.cluster:71)
[2023-04-02 16:27:04,742] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-04-02 16:27:04,770] INFO [mongodb-sink-connector|worker] Creating connector mongodb-sink-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:293)
[2023-04-02 16:27:04,774] INFO [mongodb-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:27:04,775] INFO [mongodb-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:27:04,783] INFO [mongodb-sink-connector|worker] Instantiated connector mongodb-sink-connector with version 1.10.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:315)
[2023-04-02 16:27:04,783] INFO [mongodb-sink-connector|worker] Finished creating connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:336)
[2023-04-02 16:27:04,788] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:27:04,789] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:27:04,791] INFO [mongodb-sink-connector|task-0] Creating task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:596)
[2023-04-02 16:27:04,798] INFO [mongodb-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2023-04-02 16:27:04,799] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:27:04,800] INFO [mongodb-sink-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2023-04-02 16:27:04,800] INFO [mongodb-sink-connector|task-0] Instantiated task mongodb-sink-connector-0 with version 1.10.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:610)
[2023-04-02 16:27:04,801] INFO [mongodb-sink-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:376)
[2023-04-02 16:27:04,802] INFO [mongodb-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:27:04,802] INFO [mongodb-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongodb-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:625)
[2023-04-02 16:27:04,802] INFO [mongodb-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:631)
[2023-04-02 16:27:04,802] INFO [mongodb-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:636)
[2023-04-02 16:27:04,806] INFO [mongodb-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1257)
[2023-04-02 16:27:04,807] INFO [mongodb-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:27:04,807] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:27:04,813] INFO [mongodb-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongodb-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongodb-sink-connector
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2023-04-02 16:27:04,852] WARN [mongodb-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:385)
[2023-04-02 16:27:04,852] INFO [mongodb-sink-connector|task-0] Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:27:04,852] INFO [mongodb-sink-connector|task-0] Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:27:04,852] INFO [mongodb-sink-connector|task-0] Kafka startTimeMs: 1680445624852 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:27:04,864] INFO Created connector mongodb-sink-connector (org.apache.kafka.connect.cli.ConnectStandalone:113)
[2023-04-02 16:27:04,866] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Subscribed to topic(s): emergency-data-collector, hr-data-collector, notification-channel (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2023-04-02 16:27:04,866] INFO [mongodb-sink-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:65)
[2023-04-02 16:27:04,870] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,872] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,873] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:27:04,882] INFO [mongodb-sink-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.10.0"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@58038260]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:27:04,886] INFO [mongodb-sink-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:130)
[2023-04-02 16:27:04,894] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:3, serverValue:746}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:27:04,894] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:4, serverValue:747}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:27:04,896] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=12309625} (org.mongodb.driver.cluster:71)
[2023-04-02 16:27:04,911] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:316)
[2023-04-02 16:27:04,913] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:201)
[2023-04-02 16:27:04,955] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition notification-channel-0 to 0 since the associated topicId changed from null to aNC6h-jiR52lEVqVKTD2Ug (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:27:04,956] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition emergency-data-collector-0 to 0 since the associated topicId changed from null to Yg93KKfEREu7IYKtwwu5Vg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:27:04,956] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition hr-data-collector-0 to 0 since the associated topicId changed from null to Un46eKRYRXK2oaNAf1sTKg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:27:04,958] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.clients.Metadata:287)
[2023-04-02 16:27:04,960] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator m1-yohan:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:896)
[2023-04-02 16:27:04,964] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:27:05,002] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-46f9d6cf-3efa-4315-aff0-305f1eeefbc5 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:27:05,005] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:27:05,005] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:27:05,026] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mongodb-sink-connector-0-46f9d6cf-3efa-4315-aff0-305f1eeefbc5', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:627)
[2023-04-02 16:27:05,028] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Finished assignment for group at generation 1: {connector-consumer-mongodb-sink-connector-0-46f9d6cf-3efa-4315-aff0-305f1eeefbc5=Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:710)
[2023-04-02 16:27:05,061] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mongodb-sink-connector-0-46f9d6cf-3efa-4315-aff0-305f1eeefbc5', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:802)
[2023-04-02 16:27:05,065] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Notifying assignor about the new Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:305)
[2023-04-02 16:27:05,071] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Adding newly assigned partitions: emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:317)
[2023-04-02 16:27:05,109] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:27:05,110] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition emergency-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:27:05,110] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition hr-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:27:05,142] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition notification-channel-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:27:05,145] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition emergency-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:27:05,145] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition hr-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:27:05,386] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:5, serverValue:748}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:27:05,506] ERROR [mongodb-sink-connector|task-0] Failed to put into the sink the following records: [SinkRecord{kafkaOffset=0, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=212, userEmail=duff.downey@gmail.com, @id=1, time=1680411770122}, valueSchema=null, timestamp=1680411771094, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=1, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411771097}, valueSchema=null, timestamp=1680411771097, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=2, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=206, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411771126}, valueSchema=null, timestamp=1680411771126, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=3, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=paddie.steers@gmail.com, @id=1, time=1680411771136}, valueSchema=null, timestamp=1680411771136, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=4, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411771144}, valueSchema=null, timestamp=1680411771144, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=5, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=risa.theseira@gmail.com, @id=1, time=1680411771152}, valueSchema=null, timestamp=1680411771152, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=6, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411771163}, valueSchema=null, timestamp=1680411771164, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=7, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=188, userEmail=duane.mariet@gmail.com, @id=1, time=1680411771172}, valueSchema=null, timestamp=1680411771172, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=8, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=156, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411771179}, valueSchema=null, timestamp=1680411771180, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=9, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=246, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411771187}, valueSchema=null, timestamp=1680411771188, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=10, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=levin.gregol@gmail.com, @id=1, time=1680411771196}, valueSchema=null, timestamp=1680411771196, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=11, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411771203}, valueSchema=null, timestamp=1680411771203, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=12, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=234, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411771212}, valueSchema=null, timestamp=1680411771212, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=13, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411771219}, valueSchema=null, timestamp=1680411771219, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=14, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411771226}, valueSchema=null, timestamp=1680411771226, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=15, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=155, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411771239}, valueSchema=null, timestamp=1680411771239, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=16, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=236, userEmail=reube.delooze@gmail.com, @id=1, time=1680411771248}, valueSchema=null, timestamp=1680411771248, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=17, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=205, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411771255}, valueSchema=null, timestamp=1680411771255, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=18, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411771263}, valueSchema=null, timestamp=1680411771263, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=19, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=152, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411771270}, valueSchema=null, timestamp=1680411771270, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=20, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=171, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411771276}, valueSchema=null, timestamp=1680411771276, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=21, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411771284}, valueSchema=null, timestamp=1680411771284, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=22, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=246, userEmail=kit.henken@gmail.com, @id=1, time=1680411771290}, valueSchema=null, timestamp=1680411771290, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=23, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=222, userEmail=andras.durning@gmail.com, @id=1, time=1680411771295}, valueSchema=null, timestamp=1680411771295, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=24, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=osborne.janak@gmail.com, @id=1, time=1680411771301}, valueSchema=null, timestamp=1680411771301, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=25, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=ange.losbie@gmail.com, @id=1, time=1680411771309}, valueSchema=null, timestamp=1680411771309, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=26, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=236, userEmail=christen.kytter@gmail.com, @id=1, time=1680411771318}, valueSchema=null, timestamp=1680411771318, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=27, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=189, userEmail=duff.downey@gmail.com, @id=1, time=1680411781342}, valueSchema=null, timestamp=1680411781342, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=28, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=232, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411781358}, valueSchema=null, timestamp=1680411781358, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=29, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411781368}, valueSchema=null, timestamp=1680411781368, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=30, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=164, userEmail=paddie.steers@gmail.com, @id=1, time=1680411781377}, valueSchema=null, timestamp=1680411781377, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=31, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411781384}, valueSchema=null, timestamp=1680411781384, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=32, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=233, userEmail=risa.theseira@gmail.com, @id=1, time=1680411781391}, valueSchema=null, timestamp=1680411781391, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=33, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411781397}, valueSchema=null, timestamp=1680411781398, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=34, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=194, userEmail=duane.mariet@gmail.com, @id=1, time=1680411781403}, valueSchema=null, timestamp=1680411781403, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=35, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=229, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411781408}, valueSchema=null, timestamp=1680411781408, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=36, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=215, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411781414}, valueSchema=null, timestamp=1680411781414, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=37, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=153, userEmail=levin.gregol@gmail.com, @id=1, time=1680411781419}, valueSchema=null, timestamp=1680411781419, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=38, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=166, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411781425}, valueSchema=null, timestamp=1680411781425, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=39, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=158, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411781431}, valueSchema=null, timestamp=1680411781431, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=40, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411781438}, valueSchema=null, timestamp=1680411781438, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=41, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=190, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411781444}, valueSchema=null, timestamp=1680411781444, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=42, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=230, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411781451}, valueSchema=null, timestamp=1680411781451, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=43, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=reube.delooze@gmail.com, @id=1, time=1680411781456}, valueSchema=null, timestamp=1680411781456, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=44, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=218, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411781462}, valueSchema=null, timestamp=1680411781462, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=45, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=154, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411781468}, valueSchema=null, timestamp=1680411781468, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=46, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411781475}, valueSchema=null, timestamp=1680411781475, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=47, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411781481}, valueSchema=null, timestamp=1680411781481, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=48, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=176, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411781486}, valueSchema=null, timestamp=1680411781486, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=49, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=210, userEmail=kit.henken@gmail.com, @id=1, time=1680411781492}, valueSchema=null, timestamp=1680411781493, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=50, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=andras.durning@gmail.com, @id=1, time=1680411781499}, valueSchema=null, timestamp=1680411781499, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=51, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=224, userEmail=osborne.janak@gmail.com, @id=1, time=1680411781505}, valueSchema=null, timestamp=1680411781505, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=52, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=ange.losbie@gmail.com, @id=1, time=1680411781512}, valueSchema=null, timestamp=1680411781512, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=53, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=244, userEmail=christen.kytter@gmail.com, @id=1, time=1680411781520}, valueSchema=null, timestamp=1680411781520, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=54, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=239, userEmail=duff.downey@gmail.com, @id=1, time=1680411791543}, valueSchema=null, timestamp=1680411791543, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=55, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=185, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411791559}, valueSchema=null, timestamp=1680411791559, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=56, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=189, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411791568}, valueSchema=null, timestamp=1680411791568, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=57, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=174, userEmail=paddie.steers@gmail.com, @id=1, time=1680411791576}, valueSchema=null, timestamp=1680411791576, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=58, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411791583}, valueSchema=null, timestamp=1680411791583, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=59, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=risa.theseira@gmail.com, @id=1, time=1680411791589}, valueSchema=null, timestamp=1680411791589, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=60, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=230, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411791596}, valueSchema=null, timestamp=1680411791596, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=61, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=214, userEmail=duane.mariet@gmail.com, @id=1, time=1680411791602}, valueSchema=null, timestamp=1680411791602, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=62, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=233, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411791608}, valueSchema=null, timestamp=1680411791608, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=63, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411791616}, valueSchema=null, timestamp=1680411791616, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=64, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=levin.gregol@gmail.com, @id=1, time=1680411791623}, valueSchema=null, timestamp=1680411791623, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=65, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=201, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411791628}, valueSchema=null, timestamp=1680411791628, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=66, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=240, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411791633}, valueSchema=null, timestamp=1680411791633, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=67, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411791638}, valueSchema=null, timestamp=1680411791638, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=68, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411791645}, valueSchema=null, timestamp=1680411791645, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=69, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=158, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411791649}, valueSchema=null, timestamp=1680411791649, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=70, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=188, userEmail=reube.delooze@gmail.com, @id=1, time=1680411791655}, valueSchema=null, timestamp=1680411791655, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=71, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=215, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411791660}, valueSchema=null, timestamp=1680411791660, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=72, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=242, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411791665}, valueSchema=null, timestamp=1680411791665, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=73, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=213, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411791671}, valueSchema=null, timestamp=1680411791671, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=74, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=172, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411791676}, valueSchema=null, timestamp=1680411791676, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=75, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=235, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411791682}, valueSchema=null, timestamp=1680411791682, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=76, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=199, userEmail=kit.henken@gmail.com, @id=1, time=1680411791687}, valueSchema=null, timestamp=1680411791687, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=77, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=andras.durning@gmail.com, @id=1, time=1680411791694}, valueSchema=null, timestamp=1680411791694, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=78, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=osborne.janak@gmail.com, @id=1, time=1680411791700}, valueSchema=null, timestamp=1680411791700, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=79, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=174, userEmail=ange.losbie@gmail.com, @id=1, time=1680411791705}, valueSchema=null, timestamp=1680411791705, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=80, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=209, userEmail=christen.kytter@gmail.com, @id=1, time=1680411791711}, valueSchema=null, timestamp=1680411791711, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=81, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=248, userEmail=duff.downey@gmail.com, @id=1, time=1680411801729}, valueSchema=null, timestamp=1680411801730, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=82, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=178, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411801738}, valueSchema=null, timestamp=1680411801738, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=83, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=189, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411801746}, valueSchema=null, timestamp=1680411801746, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=84, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=184, userEmail=paddie.steers@gmail.com, @id=1, time=1680411801753}, valueSchema=null, timestamp=1680411801753, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=85, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=194, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411801763}, valueSchema=null, timestamp=1680411801763, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=86, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=174, userEmail=risa.theseira@gmail.com, @id=1, time=1680411801770}, valueSchema=null, timestamp=1680411801771, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=87, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=234, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411801777}, valueSchema=null, timestamp=1680411801777, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=88, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=duane.mariet@gmail.com, @id=1, time=1680411801784}, valueSchema=null, timestamp=1680411801784, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=89, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=179, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411801789}, valueSchema=null, timestamp=1680411801789, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=90, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411801793}, valueSchema=null, timestamp=1680411801793, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=91, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=157, userEmail=levin.gregol@gmail.com, @id=1, time=1680411801799}, valueSchema=null, timestamp=1680411801799, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=92, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411801805}, valueSchema=null, timestamp=1680411801805, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=93, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=189, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411801810}, valueSchema=null, timestamp=1680411801810, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=94, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=238, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411801815}, valueSchema=null, timestamp=1680411801815, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=95, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411801820}, valueSchema=null, timestamp=1680411801820, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=96, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=188, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411801826}, valueSchema=null, timestamp=1680411801826, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=97, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=172, userEmail=reube.delooze@gmail.com, @id=1, time=1680411801831}, valueSchema=null, timestamp=1680411801831, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=98, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=243, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411801837}, valueSchema=null, timestamp=1680411801837, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=99, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=193, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411801843}, valueSchema=null, timestamp=1680411801843, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=100, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=190, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411801849}, valueSchema=null, timestamp=1680411801849, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=101, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=172, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411801855}, valueSchema=null, timestamp=1680411801855, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=102, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=231, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411801860}, valueSchema=null, timestamp=1680411801860, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=103, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=239, userEmail=kit.henken@gmail.com, @id=1, time=1680411801867}, valueSchema=null, timestamp=1680411801867, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=104, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=184, userEmail=andras.durning@gmail.com, @id=1, time=1680411801872}, valueSchema=null, timestamp=1680411801872, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=105, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=229, userEmail=osborne.janak@gmail.com, @id=1, time=1680411801877}, valueSchema=null, timestamp=1680411801877, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=106, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=ange.losbie@gmail.com, @id=1, time=1680411801883}, valueSchema=null, timestamp=1680411801883, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=107, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=christen.kytter@gmail.com, @id=1, time=1680411801890}, valueSchema=null, timestamp=1680411801890, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=108, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=193, userEmail=duff.downey@gmail.com, @id=1, time=1680411811905}, valueSchema=null, timestamp=1680411811906, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=109, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411811912}, valueSchema=null, timestamp=1680411811912, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=110, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411811919}, valueSchema=null, timestamp=1680411811919, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=111, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=246, userEmail=paddie.steers@gmail.com, @id=1, time=1680411811925}, valueSchema=null, timestamp=1680411811925, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=112, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=240, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411811930}, valueSchema=null, timestamp=1680411811930, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=113, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=206, userEmail=risa.theseira@gmail.com, @id=1, time=1680411811936}, valueSchema=null, timestamp=1680411811936, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=114, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=211, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411811940}, valueSchema=null, timestamp=1680411811940, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=115, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=duane.mariet@gmail.com, @id=1, time=1680411811945}, valueSchema=null, timestamp=1680411811945, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=116, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411811950}, valueSchema=null, timestamp=1680411811950, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=117, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=171, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411811955}, valueSchema=null, timestamp=1680411811955, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=118, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=229, userEmail=levin.gregol@gmail.com, @id=1, time=1680411811959}, valueSchema=null, timestamp=1680411811959, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=119, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=214, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411811964}, valueSchema=null, timestamp=1680411811964, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=120, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411811969}, valueSchema=null, timestamp=1680411811969, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=121, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=221, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411811975}, valueSchema=null, timestamp=1680411811975, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=122, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=243, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411811980}, valueSchema=null, timestamp=1680411811980, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=123, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=246, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411811986}, valueSchema=null, timestamp=1680411811986, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=124, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=reube.delooze@gmail.com, @id=1, time=1680411811991}, valueSchema=null, timestamp=1680411811991, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=125, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=196, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411811998}, valueSchema=null, timestamp=1680411811998, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=126, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=151, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411812006}, valueSchema=null, timestamp=1680411812006, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=127, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411812015}, valueSchema=null, timestamp=1680411812015, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=128, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411812024}, valueSchema=null, timestamp=1680411812024, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=129, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411812030}, valueSchema=null, timestamp=1680411812030, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=130, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=195, userEmail=kit.henken@gmail.com, @id=1, time=1680411812035}, valueSchema=null, timestamp=1680411812035, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=131, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=andras.durning@gmail.com, @id=1, time=1680411812040}, valueSchema=null, timestamp=1680411812040, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=132, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=178, userEmail=osborne.janak@gmail.com, @id=1, time=1680411812045}, valueSchema=null, timestamp=1680411812045, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=133, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=ange.losbie@gmail.com, @id=1, time=1680411812050}, valueSchema=null, timestamp=1680411812050, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=134, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=christen.kytter@gmail.com, @id=1, time=1680411812055}, valueSchema=null, timestamp=1680411812055, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=135, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=duff.downey@gmail.com, @id=1, time=1680411822063}, valueSchema=null, timestamp=1680411822063, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=136, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=204, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411822069}, valueSchema=null, timestamp=1680411822069, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=137, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411822073}, valueSchema=null, timestamp=1680411822073, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=138, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=163, userEmail=paddie.steers@gmail.com, @id=1, time=1680411822078}, valueSchema=null, timestamp=1680411822078, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=139, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411822083}, valueSchema=null, timestamp=1680411822083, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=140, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=189, userEmail=risa.theseira@gmail.com, @id=1, time=1680411822088}, valueSchema=null, timestamp=1680411822088, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=141, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411822092}, valueSchema=null, timestamp=1680411822092, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=142, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=190, userEmail=duane.mariet@gmail.com, @id=1, time=1680411822097}, valueSchema=null, timestamp=1680411822097, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=143, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411822102}, valueSchema=null, timestamp=1680411822102, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=144, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=232, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411822107}, valueSchema=null, timestamp=1680411822107, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=145, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=205, userEmail=levin.gregol@gmail.com, @id=1, time=1680411822113}, valueSchema=null, timestamp=1680411822114, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=146, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=221, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411822118}, valueSchema=null, timestamp=1680411822118, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=147, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411822123}, valueSchema=null, timestamp=1680411822123, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=148, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411822128}, valueSchema=null, timestamp=1680411822128, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=149, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411822134}, valueSchema=null, timestamp=1680411822134, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=150, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=230, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411822139}, valueSchema=null, timestamp=1680411822139, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=151, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=reube.delooze@gmail.com, @id=1, time=1680411822144}, valueSchema=null, timestamp=1680411822144, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=152, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411822149}, valueSchema=null, timestamp=1680411822149, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=153, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411822153}, valueSchema=null, timestamp=1680411822153, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=154, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=163, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411822158}, valueSchema=null, timestamp=1680411822158, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=155, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=181, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411822163}, valueSchema=null, timestamp=1680411822163, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=156, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=205, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411822168}, valueSchema=null, timestamp=1680411822168, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=157, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=156, userEmail=kit.henken@gmail.com, @id=1, time=1680411822172}, valueSchema=null, timestamp=1680411822172, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=158, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=231, userEmail=andras.durning@gmail.com, @id=1, time=1680411822177}, valueSchema=null, timestamp=1680411822177, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=159, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=osborne.janak@gmail.com, @id=1, time=1680411822182}, valueSchema=null, timestamp=1680411822182, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=160, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=179, userEmail=ange.losbie@gmail.com, @id=1, time=1680411822187}, valueSchema=null, timestamp=1680411822187, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=161, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=190, userEmail=christen.kytter@gmail.com, @id=1, time=1680411822192}, valueSchema=null, timestamp=1680411822192, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=162, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=201, userEmail=duff.downey@gmail.com, @id=1, time=1680411832199}, valueSchema=null, timestamp=1680411832199, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=163, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=239, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411832204}, valueSchema=null, timestamp=1680411832204, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=164, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=221, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411832209}, valueSchema=null, timestamp=1680411832209, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=165, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=158, userEmail=paddie.steers@gmail.com, @id=1, time=1680411832213}, valueSchema=null, timestamp=1680411832213, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=166, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=246, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411832217}, valueSchema=null, timestamp=1680411832217, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=167, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=235, userEmail=risa.theseira@gmail.com, @id=1, time=1680411832220}, valueSchema=null, timestamp=1680411832221, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=168, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411832224}, valueSchema=null, timestamp=1680411832225, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=169, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=224, userEmail=duane.mariet@gmail.com, @id=1, time=1680411832229}, valueSchema=null, timestamp=1680411832230, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=170, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=242, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411832235}, valueSchema=null, timestamp=1680411832235, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=171, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=206, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411832240}, valueSchema=null, timestamp=1680411832240, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=172, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=231, userEmail=levin.gregol@gmail.com, @id=1, time=1680411832245}, valueSchema=null, timestamp=1680411832245, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=173, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411832249}, valueSchema=null, timestamp=1680411832249, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=174, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=188, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411832254}, valueSchema=null, timestamp=1680411832254, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=175, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=245, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411832260}, valueSchema=null, timestamp=1680411832260, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=176, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=238, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411832265}, valueSchema=null, timestamp=1680411832265, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=177, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411832269}, valueSchema=null, timestamp=1680411832269, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=178, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=222, userEmail=reube.delooze@gmail.com, @id=1, time=1680411832274}, valueSchema=null, timestamp=1680411832274, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=179, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=240, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411832278}, valueSchema=null, timestamp=1680411832279, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=180, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=172, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411832284}, valueSchema=null, timestamp=1680411832284, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=181, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=160, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411832288}, valueSchema=null, timestamp=1680411832288, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=182, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411832292}, valueSchema=null, timestamp=1680411832293, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=183, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411832297}, valueSchema=null, timestamp=1680411832297, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=184, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=kit.henken@gmail.com, @id=1, time=1680411832301}, valueSchema=null, timestamp=1680411832301, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=185, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=209, userEmail=andras.durning@gmail.com, @id=1, time=1680411832306}, valueSchema=null, timestamp=1680411832306, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=186, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=236, userEmail=osborne.janak@gmail.com, @id=1, time=1680411832311}, valueSchema=null, timestamp=1680411832311, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=187, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=197, userEmail=ange.losbie@gmail.com, @id=1, time=1680411832315}, valueSchema=null, timestamp=1680411832315, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=188, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=234, userEmail=christen.kytter@gmail.com, @id=1, time=1680411832320}, valueSchema=null, timestamp=1680411832320, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=189, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=188, userEmail=duff.downey@gmail.com, @id=1, time=1680411842339}, valueSchema=null, timestamp=1680411842339, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=190, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=181, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411842347}, valueSchema=null, timestamp=1680411842347, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=191, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411842353}, valueSchema=null, timestamp=1680411842353, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=192, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=paddie.steers@gmail.com, @id=1, time=1680411842360}, valueSchema=null, timestamp=1680411842360, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=193, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411842366}, valueSchema=null, timestamp=1680411842366, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=194, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=157, userEmail=risa.theseira@gmail.com, @id=1, time=1680411842371}, valueSchema=null, timestamp=1680411842371, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=195, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=229, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411842376}, valueSchema=null, timestamp=1680411842376, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=196, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=duane.mariet@gmail.com, @id=1, time=1680411842380}, valueSchema=null, timestamp=1680411842380, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=197, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=155, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411842384}, valueSchema=null, timestamp=1680411842384, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=198, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=154, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411842388}, valueSchema=null, timestamp=1680411842388, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=199, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=levin.gregol@gmail.com, @id=1, time=1680411842393}, valueSchema=null, timestamp=1680411842393, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=200, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=206, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411842397}, valueSchema=null, timestamp=1680411842397, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=201, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=151, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411842402}, valueSchema=null, timestamp=1680411842402, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=202, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411842407}, valueSchema=null, timestamp=1680411842407, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=203, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=152, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411842413}, valueSchema=null, timestamp=1680411842413, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=204, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411842418}, valueSchema=null, timestamp=1680411842418, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=205, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=178, userEmail=reube.delooze@gmail.com, @id=1, time=1680411842422}, valueSchema=null, timestamp=1680411842422, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=206, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=213, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411842427}, valueSchema=null, timestamp=1680411842427, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=207, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=242, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411842431}, valueSchema=null, timestamp=1680411842431, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=208, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=238, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411842436}, valueSchema=null, timestamp=1680411842436, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=209, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=211, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411842440}, valueSchema=null, timestamp=1680411842440, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=210, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411842444}, valueSchema=null, timestamp=1680411842444, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=211, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=182, userEmail=kit.henken@gmail.com, @id=1, time=1680411842449}, valueSchema=null, timestamp=1680411842449, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=212, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=246, userEmail=andras.durning@gmail.com, @id=1, time=1680411842453}, valueSchema=null, timestamp=1680411842453, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=213, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=174, userEmail=osborne.janak@gmail.com, @id=1, time=1680411842459}, valueSchema=null, timestamp=1680411842459, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=214, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=ange.losbie@gmail.com, @id=1, time=1680411842464}, valueSchema=null, timestamp=1680411842464, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=215, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=christen.kytter@gmail.com, @id=1, time=1680411842468}, valueSchema=null, timestamp=1680411842468, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=216, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=222, userEmail=duff.downey@gmail.com, @id=1, time=1680411852482}, valueSchema=null, timestamp=1680411852482, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=217, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=182, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411852488}, valueSchema=null, timestamp=1680411852488, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=218, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=159, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411852494}, valueSchema=null, timestamp=1680411852494, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=219, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=159, userEmail=paddie.steers@gmail.com, @id=1, time=1680411852500}, valueSchema=null, timestamp=1680411852500, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=220, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=171, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411852505}, valueSchema=null, timestamp=1680411852505, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=221, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=205, userEmail=risa.theseira@gmail.com, @id=1, time=1680411852511}, valueSchema=null, timestamp=1680411852511, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=222, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=194, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411852515}, valueSchema=null, timestamp=1680411852515, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=223, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=duane.mariet@gmail.com, @id=1, time=1680411852520}, valueSchema=null, timestamp=1680411852520, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=224, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=224, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411852526}, valueSchema=null, timestamp=1680411852526, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=225, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=206, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411852531}, valueSchema=null, timestamp=1680411852531, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=226, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=152, userEmail=levin.gregol@gmail.com, @id=1, time=1680411852538}, valueSchema=null, timestamp=1680411852538, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=227, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=200, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411852547}, valueSchema=null, timestamp=1680411852547, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=228, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=167, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411852553}, valueSchema=null, timestamp=1680411852553, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=229, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=152, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411852558}, valueSchema=null, timestamp=1680411852558, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=230, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411852563}, valueSchema=null, timestamp=1680411852563, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=231, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=169, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411852568}, valueSchema=null, timestamp=1680411852568, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=232, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=reube.delooze@gmail.com, @id=1, time=1680411852573}, valueSchema=null, timestamp=1680411852573, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=233, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411852578}, valueSchema=null, timestamp=1680411852578, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=234, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=220, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411852583}, valueSchema=null, timestamp=1680411852583, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=235, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=183, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411852589}, valueSchema=null, timestamp=1680411852589, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=236, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411852594}, valueSchema=null, timestamp=1680411852594, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=237, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411852600}, valueSchema=null, timestamp=1680411852600, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=238, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=kit.henken@gmail.com, @id=1, time=1680411852606}, valueSchema=null, timestamp=1680411852606, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=239, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=169, userEmail=andras.durning@gmail.com, @id=1, time=1680411852611}, valueSchema=null, timestamp=1680411852611, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=240, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=osborne.janak@gmail.com, @id=1, time=1680411852616}, valueSchema=null, timestamp=1680411852616, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=241, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=ange.losbie@gmail.com, @id=1, time=1680411852621}, valueSchema=null, timestamp=1680411852621, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=242, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=christen.kytter@gmail.com, @id=1, time=1680411852627}, valueSchema=null, timestamp=1680411852627, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=243, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=duff.downey@gmail.com, @id=1, time=1680411862653}, valueSchema=null, timestamp=1680411862653, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=244, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=153, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411862668}, valueSchema=null, timestamp=1680411862668, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=245, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411862674}, valueSchema=null, timestamp=1680411862674, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=246, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=paddie.steers@gmail.com, @id=1, time=1680411862680}, valueSchema=null, timestamp=1680411862680, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=247, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=170, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411862685}, valueSchema=null, timestamp=1680411862685, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=248, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=197, userEmail=risa.theseira@gmail.com, @id=1, time=1680411862690}, valueSchema=null, timestamp=1680411862690, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=249, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411862695}, valueSchema=null, timestamp=1680411862695, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=250, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=229, userEmail=duane.mariet@gmail.com, @id=1, time=1680411862700}, valueSchema=null, timestamp=1680411862700, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=251, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=185, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411862705}, valueSchema=null, timestamp=1680411862705, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=252, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=225, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411862710}, valueSchema=null, timestamp=1680411862710, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=253, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=171, userEmail=levin.gregol@gmail.com, @id=1, time=1680411862715}, valueSchema=null, timestamp=1680411862715, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=254, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=245, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411862721}, valueSchema=null, timestamp=1680411862721, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=255, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=223, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411862727}, valueSchema=null, timestamp=1680411862727, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=256, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411862735}, valueSchema=null, timestamp=1680411862735, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=257, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411862741}, valueSchema=null, timestamp=1680411862741, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=258, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=250, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411862748}, valueSchema=null, timestamp=1680411862748, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=259, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=223, userEmail=reube.delooze@gmail.com, @id=1, time=1680411862754}, valueSchema=null, timestamp=1680411862754, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=260, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411862760}, valueSchema=null, timestamp=1680411862760, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=261, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=159, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411862768}, valueSchema=null, timestamp=1680411862768, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=262, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411862774}, valueSchema=null, timestamp=1680411862774, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=263, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=222, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411862778}, valueSchema=null, timestamp=1680411862778, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=264, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=187, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411862783}, valueSchema=null, timestamp=1680411862783, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=265, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=157, userEmail=kit.henken@gmail.com, @id=1, time=1680411862788}, valueSchema=null, timestamp=1680411862788, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=266, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=andras.durning@gmail.com, @id=1, time=1680411862795}, valueSchema=null, timestamp=1680411862795, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=267, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=229, userEmail=osborne.janak@gmail.com, @id=1, time=1680411862803}, valueSchema=null, timestamp=1680411862803, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=268, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=184, userEmail=ange.losbie@gmail.com, @id=1, time=1680411862809}, valueSchema=null, timestamp=1680411862809, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=269, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=179, userEmail=christen.kytter@gmail.com, @id=1, time=1680411862815}, valueSchema=null, timestamp=1680411862815, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=270, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=157, userEmail=duff.downey@gmail.com, @id=1, time=1680411872837}, valueSchema=null, timestamp=1680411872837, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=271, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411872847}, valueSchema=null, timestamp=1680411872847, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=272, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411872856}, valueSchema=null, timestamp=1680411872856, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=273, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=paddie.steers@gmail.com, @id=1, time=1680411872862}, valueSchema=null, timestamp=1680411872862, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=274, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=233, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411872868}, valueSchema=null, timestamp=1680411872868, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=275, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=risa.theseira@gmail.com, @id=1, time=1680411872875}, valueSchema=null, timestamp=1680411872875, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=276, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=155, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411872880}, valueSchema=null, timestamp=1680411872881, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=277, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=duane.mariet@gmail.com, @id=1, time=1680411872885}, valueSchema=null, timestamp=1680411872885, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=278, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=228, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411872890}, valueSchema=null, timestamp=1680411872890, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=279, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=165, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411872894}, valueSchema=null, timestamp=1680411872894, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=280, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=levin.gregol@gmail.com, @id=1, time=1680411872898}, valueSchema=null, timestamp=1680411872898, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=281, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411872902}, valueSchema=null, timestamp=1680411872902, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=282, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=241, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411872906}, valueSchema=null, timestamp=1680411872906, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=283, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411872910}, valueSchema=null, timestamp=1680411872910, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=284, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=164, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411872915}, valueSchema=null, timestamp=1680411872915, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=285, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=178, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411872919}, valueSchema=null, timestamp=1680411872919, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=286, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=reube.delooze@gmail.com, @id=1, time=1680411872923}, valueSchema=null, timestamp=1680411872923, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=287, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=235, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411872927}, valueSchema=null, timestamp=1680411872927, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=288, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411872931}, valueSchema=null, timestamp=1680411872931, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=289, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=236, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411872936}, valueSchema=null, timestamp=1680411872936, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=290, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411872942}, valueSchema=null, timestamp=1680411872942, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=291, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411872948}, valueSchema=null, timestamp=1680411872948, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=292, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=kit.henken@gmail.com, @id=1, time=1680411872953}, valueSchema=null, timestamp=1680411872953, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=293, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=andras.durning@gmail.com, @id=1, time=1680411872958}, valueSchema=null, timestamp=1680411872958, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=294, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=201, userEmail=osborne.janak@gmail.com, @id=1, time=1680411872963}, valueSchema=null, timestamp=1680411872963, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=295, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=158, userEmail=ange.losbie@gmail.com, @id=1, time=1680411872968}, valueSchema=null, timestamp=1680411872968, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=296, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=184, userEmail=christen.kytter@gmail.com, @id=1, time=1680411872972}, valueSchema=null, timestamp=1680411872972, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=297, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=duff.downey@gmail.com, @id=1, time=1680411883010}, valueSchema=null, timestamp=1680411883010, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=298, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=153, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411883022}, valueSchema=null, timestamp=1680411883022, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=299, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411883029}, valueSchema=null, timestamp=1680411883029, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=300, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=222, userEmail=paddie.steers@gmail.com, @id=1, time=1680411883034}, valueSchema=null, timestamp=1680411883034, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=301, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=174, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411883041}, valueSchema=null, timestamp=1680411883041, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=302, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=241, userEmail=risa.theseira@gmail.com, @id=1, time=1680411883045}, valueSchema=null, timestamp=1680411883046, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=303, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=156, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411883050}, valueSchema=null, timestamp=1680411883050, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=304, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=duane.mariet@gmail.com, @id=1, time=1680411883055}, valueSchema=null, timestamp=1680411883055, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=305, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411883059}, valueSchema=null, timestamp=1680411883059, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=306, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411883063}, valueSchema=null, timestamp=1680411883063, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=307, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=levin.gregol@gmail.com, @id=1, time=1680411883068}, valueSchema=null, timestamp=1680411883068, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=308, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=205, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411883073}, valueSchema=null, timestamp=1680411883073, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=309, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=191, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411883078}, valueSchema=null, timestamp=1680411883078, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=310, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=193, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411883083}, valueSchema=null, timestamp=1680411883083, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=311, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411883087}, valueSchema=null, timestamp=1680411883087, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=312, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411883091}, valueSchema=null, timestamp=1680411883091, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=313, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=reube.delooze@gmail.com, @id=1, time=1680411883095}, valueSchema=null, timestamp=1680411883095, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=314, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=218, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411883099}, valueSchema=null, timestamp=1680411883099, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=315, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=232, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411883102}, valueSchema=null, timestamp=1680411883102, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=316, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=200, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411883106}, valueSchema=null, timestamp=1680411883106, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=317, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=151, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411883110}, valueSchema=null, timestamp=1680411883110, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=318, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=215, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411883113}, valueSchema=null, timestamp=1680411883113, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=319, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=kit.henken@gmail.com, @id=1, time=1680411883117}, valueSchema=null, timestamp=1680411883117, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=320, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=214, userEmail=andras.durning@gmail.com, @id=1, time=1680411883122}, valueSchema=null, timestamp=1680411883122, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=321, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=osborne.janak@gmail.com, @id=1, time=1680411883127}, valueSchema=null, timestamp=1680411883127, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=322, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=ange.losbie@gmail.com, @id=1, time=1680411883131}, valueSchema=null, timestamp=1680411883131, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=323, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=213, userEmail=christen.kytter@gmail.com, @id=1, time=1680411883135}, valueSchema=null, timestamp=1680411883135, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=324, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=duff.downey@gmail.com, @id=1, time=1680411893160}, valueSchema=null, timestamp=1680411893160, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=325, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=184, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411893171}, valueSchema=null, timestamp=1680411893171, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=326, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=215, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411893179}, valueSchema=null, timestamp=1680411893179, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=327, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=204, userEmail=paddie.steers@gmail.com, @id=1, time=1680411893185}, valueSchema=null, timestamp=1680411893185, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=328, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=204, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411893190}, valueSchema=null, timestamp=1680411893190, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=329, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=245, userEmail=risa.theseira@gmail.com, @id=1, time=1680411893195}, valueSchema=null, timestamp=1680411893195, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=330, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=197, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411893201}, valueSchema=null, timestamp=1680411893201, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=331, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=243, userEmail=duane.mariet@gmail.com, @id=1, time=1680411893208}, valueSchema=null, timestamp=1680411893208, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=332, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411893214}, valueSchema=null, timestamp=1680411893214, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=333, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411893219}, valueSchema=null, timestamp=1680411893219, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=334, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=212, userEmail=levin.gregol@gmail.com, @id=1, time=1680411893225}, valueSchema=null, timestamp=1680411893225, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=335, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411893230}, valueSchema=null, timestamp=1680411893230, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=336, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=223, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411893234}, valueSchema=null, timestamp=1680411893234, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=337, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=158, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411893239}, valueSchema=null, timestamp=1680411893239, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=338, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411893244}, valueSchema=null, timestamp=1680411893244, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=339, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=184, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411893248}, valueSchema=null, timestamp=1680411893248, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=340, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=172, userEmail=reube.delooze@gmail.com, @id=1, time=1680411893252}, valueSchema=null, timestamp=1680411893252, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=341, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=170, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411893256}, valueSchema=null, timestamp=1680411893256, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=342, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=205, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411893260}, valueSchema=null, timestamp=1680411893260, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=343, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411893264}, valueSchema=null, timestamp=1680411893264, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=344, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=200, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411893268}, valueSchema=null, timestamp=1680411893268, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=345, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=209, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411893271}, valueSchema=null, timestamp=1680411893271, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=346, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=212, userEmail=kit.henken@gmail.com, @id=1, time=1680411893275}, valueSchema=null, timestamp=1680411893275, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=347, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=andras.durning@gmail.com, @id=1, time=1680411893278}, valueSchema=null, timestamp=1680411893278, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=348, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=osborne.janak@gmail.com, @id=1, time=1680411893282}, valueSchema=null, timestamp=1680411893282, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=349, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=ange.losbie@gmail.com, @id=1, time=1680411893286}, valueSchema=null, timestamp=1680411893286, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=350, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=166, userEmail=christen.kytter@gmail.com, @id=1, time=1680411893290}, valueSchema=null, timestamp=1680411893290, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=351, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=166, userEmail=duff.downey@gmail.com, @id=1, time=1680411903334}, valueSchema=null, timestamp=1680411903334, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=352, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411903344}, valueSchema=null, timestamp=1680411903344, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=353, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=243, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411903349}, valueSchema=null, timestamp=1680411903349, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=354, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=232, userEmail=paddie.steers@gmail.com, @id=1, time=1680411903355}, valueSchema=null, timestamp=1680411903355, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=355, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=172, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411903359}, valueSchema=null, timestamp=1680411903359, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=356, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=155, userEmail=risa.theseira@gmail.com, @id=1, time=1680411903364}, valueSchema=null, timestamp=1680411903364, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=357, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=250, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411903369}, valueSchema=null, timestamp=1680411903369, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=358, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=210, userEmail=duane.mariet@gmail.com, @id=1, time=1680411903374}, valueSchema=null, timestamp=1680411903374, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=359, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411903379}, valueSchema=null, timestamp=1680411903379, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=360, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=233, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411903384}, valueSchema=null, timestamp=1680411903384, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=361, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=196, userEmail=levin.gregol@gmail.com, @id=1, time=1680411903389}, valueSchema=null, timestamp=1680411903389, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=362, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=235, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411903394}, valueSchema=null, timestamp=1680411903394, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=363, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=209, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411903398}, valueSchema=null, timestamp=1680411903398, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=364, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=224, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411903403}, valueSchema=null, timestamp=1680411903403, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=365, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=173, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411903407}, valueSchema=null, timestamp=1680411903407, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=366, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=151, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411903411}, valueSchema=null, timestamp=1680411903411, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=367, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=250, userEmail=reube.delooze@gmail.com, @id=1, time=1680411903415}, valueSchema=null, timestamp=1680411903415, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=368, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411903419}, valueSchema=null, timestamp=1680411903419, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=369, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=245, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411903424}, valueSchema=null, timestamp=1680411903424, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=370, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411903428}, valueSchema=null, timestamp=1680411903428, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=371, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=156, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411903432}, valueSchema=null, timestamp=1680411903432, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=372, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=200, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411903436}, valueSchema=null, timestamp=1680411903436, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=373, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=kit.henken@gmail.com, @id=1, time=1680411903439}, valueSchema=null, timestamp=1680411903439, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=374, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=167, userEmail=andras.durning@gmail.com, @id=1, time=1680411903444}, valueSchema=null, timestamp=1680411903444, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=375, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=154, userEmail=osborne.janak@gmail.com, @id=1, time=1680411903448}, valueSchema=null, timestamp=1680411903448, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=376, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=234, userEmail=ange.losbie@gmail.com, @id=1, time=1680411903451}, valueSchema=null, timestamp=1680411903451, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=377, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=christen.kytter@gmail.com, @id=1, time=1680411903455}, valueSchema=null, timestamp=1680411903455, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=378, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=167, userEmail=duff.downey@gmail.com, @id=1, time=1680411913471}, valueSchema=null, timestamp=1680411913472, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=379, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411913483}, valueSchema=null, timestamp=1680411913483, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=380, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=179, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411913492}, valueSchema=null, timestamp=1680411913492, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=381, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=paddie.steers@gmail.com, @id=1, time=1680411913498}, valueSchema=null, timestamp=1680411913498, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=382, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=223, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411913505}, valueSchema=null, timestamp=1680411913505, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=383, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=risa.theseira@gmail.com, @id=1, time=1680411913511}, valueSchema=null, timestamp=1680411913511, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=384, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=211, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411913516}, valueSchema=null, timestamp=1680411913516, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=385, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=215, userEmail=duane.mariet@gmail.com, @id=1, time=1680411913520}, valueSchema=null, timestamp=1680411913521, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=386, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=221, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411913524}, valueSchema=null, timestamp=1680411913524, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=387, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411913528}, valueSchema=null, timestamp=1680411913528, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=388, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=169, userEmail=levin.gregol@gmail.com, @id=1, time=1680411913531}, valueSchema=null, timestamp=1680411913532, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=389, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=150, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411913535}, valueSchema=null, timestamp=1680411913535, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=390, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411913539}, valueSchema=null, timestamp=1680411913539, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=391, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=201, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411913542}, valueSchema=null, timestamp=1680411913542, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=392, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=221, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411913546}, valueSchema=null, timestamp=1680411913546, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=393, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=151, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411913549}, valueSchema=null, timestamp=1680411913549, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=394, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=reube.delooze@gmail.com, @id=1, time=1680411913552}, valueSchema=null, timestamp=1680411913552, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=395, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411913556}, valueSchema=null, timestamp=1680411913556, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=396, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=170, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411913559}, valueSchema=null, timestamp=1680411913559, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=397, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=151, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411913562}, valueSchema=null, timestamp=1680411913562, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=398, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=164, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411913566}, valueSchema=null, timestamp=1680411913566, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=399, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=238, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411913570}, valueSchema=null, timestamp=1680411913570, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=400, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=152, userEmail=kit.henken@gmail.com, @id=1, time=1680411913573}, valueSchema=null, timestamp=1680411913573, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=401, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=249, userEmail=andras.durning@gmail.com, @id=1, time=1680411913578}, valueSchema=null, timestamp=1680411913578, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=402, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=190, userEmail=osborne.janak@gmail.com, @id=1, time=1680411913581}, valueSchema=null, timestamp=1680411913581, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=403, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=ange.losbie@gmail.com, @id=1, time=1680411913585}, valueSchema=null, timestamp=1680411913585, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=404, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=155, userEmail=christen.kytter@gmail.com, @id=1, time=1680411913588}, valueSchema=null, timestamp=1680411913589, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=405, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=duff.downey@gmail.com, @id=1, time=1680411923608}, valueSchema=null, timestamp=1680411923609, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=406, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411923620}, valueSchema=null, timestamp=1680411923621, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=407, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411923629}, valueSchema=null, timestamp=1680411923629, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=408, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=199, userEmail=paddie.steers@gmail.com, @id=1, time=1680411923636}, valueSchema=null, timestamp=1680411923636, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=409, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411923642}, valueSchema=null, timestamp=1680411923642, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=410, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=226, userEmail=risa.theseira@gmail.com, @id=1, time=1680411923648}, valueSchema=null, timestamp=1680411923648, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=411, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=208, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411923654}, valueSchema=null, timestamp=1680411923654, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=412, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=248, userEmail=duane.mariet@gmail.com, @id=1, time=1680411923658}, valueSchema=null, timestamp=1680411923659, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=413, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=220, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411923664}, valueSchema=null, timestamp=1680411923664, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=414, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411923668}, valueSchema=null, timestamp=1680411923668, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=415, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=248, userEmail=levin.gregol@gmail.com, @id=1, time=1680411923672}, valueSchema=null, timestamp=1680411923672, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=416, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=180, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411923675}, valueSchema=null, timestamp=1680411923675, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=417, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=178, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411923679}, valueSchema=null, timestamp=1680411923679, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=418, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=159, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411923682}, valueSchema=null, timestamp=1680411923682, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=419, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411923685}, valueSchema=null, timestamp=1680411923685, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=420, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=155, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411923688}, valueSchema=null, timestamp=1680411923689, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=421, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=207, userEmail=reube.delooze@gmail.com, @id=1, time=1680411923692}, valueSchema=null, timestamp=1680411923692, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=422, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411923695}, valueSchema=null, timestamp=1680411923695, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=423, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=244, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411923699}, valueSchema=null, timestamp=1680411923699, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=424, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411923702}, valueSchema=null, timestamp=1680411923702, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=425, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=233, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411923705}, valueSchema=null, timestamp=1680411923705, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=426, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411923708}, valueSchema=null, timestamp=1680411923708, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=427, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=241, userEmail=kit.henken@gmail.com, @id=1, time=1680411923710}, valueSchema=null, timestamp=1680411923710, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=428, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=223, userEmail=andras.durning@gmail.com, @id=1, time=1680411923713}, valueSchema=null, timestamp=1680411923713, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=429, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=osborne.janak@gmail.com, @id=1, time=1680411923716}, valueSchema=null, timestamp=1680411923716, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=430, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=174, userEmail=ange.losbie@gmail.com, @id=1, time=1680411923719}, valueSchema=null, timestamp=1680411923719, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=431, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=christen.kytter@gmail.com, @id=1, time=1680411923722}, valueSchema=null, timestamp=1680411923722, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=432, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=171, userEmail=duff.downey@gmail.com, @id=1, time=1680411933744}, valueSchema=null, timestamp=1680411933745, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=433, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=242, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411933753}, valueSchema=null, timestamp=1680411933754, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=434, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=235, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411933758}, valueSchema=null, timestamp=1680411933758, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=435, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=paddie.steers@gmail.com, @id=1, time=1680411933763}, valueSchema=null, timestamp=1680411933763, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=436, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=182, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411933767}, valueSchema=null, timestamp=1680411933767, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=437, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=243, userEmail=risa.theseira@gmail.com, @id=1, time=1680411933771}, valueSchema=null, timestamp=1680411933771, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=438, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=186, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411933775}, valueSchema=null, timestamp=1680411933775, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=439, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=duane.mariet@gmail.com, @id=1, time=1680411933778}, valueSchema=null, timestamp=1680411933779, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=440, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=200, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411933783}, valueSchema=null, timestamp=1680411933783, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=441, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=164, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411933787}, valueSchema=null, timestamp=1680411933787, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=442, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=193, userEmail=levin.gregol@gmail.com, @id=1, time=1680411933791}, valueSchema=null, timestamp=1680411933791, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=443, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=247, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411933795}, valueSchema=null, timestamp=1680411933795, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=444, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=232, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411933799}, valueSchema=null, timestamp=1680411933799, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=445, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=244, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411933802}, valueSchema=null, timestamp=1680411933802, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=446, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=235, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411933806}, valueSchema=null, timestamp=1680411933806, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=447, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=219, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411933810}, valueSchema=null, timestamp=1680411933810, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=448, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=185, userEmail=reube.delooze@gmail.com, @id=1, time=1680411933813}, valueSchema=null, timestamp=1680411933813, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=449, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=203, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411933817}, valueSchema=null, timestamp=1680411933817, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=450, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=177, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411933820}, valueSchema=null, timestamp=1680411933820, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=451, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411933824}, valueSchema=null, timestamp=1680411933824, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=452, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=231, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411933829}, valueSchema=null, timestamp=1680411933829, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=453, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=237, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411933834}, valueSchema=null, timestamp=1680411933834, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=454, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=181, userEmail=kit.henken@gmail.com, @id=1, time=1680411933839}, valueSchema=null, timestamp=1680411933839, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=455, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=187, userEmail=andras.durning@gmail.com, @id=1, time=1680411933843}, valueSchema=null, timestamp=1680411933843, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=456, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=153, userEmail=osborne.janak@gmail.com, @id=1, time=1680411933846}, valueSchema=null, timestamp=1680411933846, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=457, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=168, userEmail=ange.losbie@gmail.com, @id=1, time=1680411933849}, valueSchema=null, timestamp=1680411933849, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=458, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=160, userEmail=christen.kytter@gmail.com, @id=1, time=1680411933852}, valueSchema=null, timestamp=1680411933852, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=459, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=236, userEmail=duff.downey@gmail.com, @id=1, time=1680411943872}, valueSchema=null, timestamp=1680411943872, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=460, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=167, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411943884}, valueSchema=null, timestamp=1680411943884, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=461, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=227, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411943891}, valueSchema=null, timestamp=1680411943891, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=462, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=202, userEmail=paddie.steers@gmail.com, @id=1, time=1680411943898}, valueSchema=null, timestamp=1680411943898, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=463, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=217, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411943904}, valueSchema=null, timestamp=1680411943904, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=464, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=211, userEmail=risa.theseira@gmail.com, @id=1, time=1680411943909}, valueSchema=null, timestamp=1680411943909, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=465, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=244, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411943913}, valueSchema=null, timestamp=1680411943913, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=466, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=197, userEmail=duane.mariet@gmail.com, @id=1, time=1680411943918}, valueSchema=null, timestamp=1680411943918, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=467, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411943921}, valueSchema=null, timestamp=1680411943921, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=468, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=212, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411943926}, valueSchema=null, timestamp=1680411943926, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=469, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=171, userEmail=levin.gregol@gmail.com, @id=1, time=1680411943930}, valueSchema=null, timestamp=1680411943930, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=470, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411943934}, valueSchema=null, timestamp=1680411943934, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=471, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=210, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411943937}, valueSchema=null, timestamp=1680411943937, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=472, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=234, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411943941}, valueSchema=null, timestamp=1680411943941, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=473, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=196, userEmail=marie-ann.funnell@gmail.com, @id=1, time=1680411943944}, valueSchema=null, timestamp=1680411943944, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=474, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=210, userEmail=tuner.waitland@gmail.com, @id=1, time=1680411943948}, valueSchema=null, timestamp=1680411943948, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=475, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=239, userEmail=reube.delooze@gmail.com, @id=1, time=1680411943952}, valueSchema=null, timestamp=1680411943952, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=476, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=178, userEmail=shara.denisyev@gmail.com, @id=1, time=1680411943956}, valueSchema=null, timestamp=1680411943956, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=477, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=152, userEmail=leah.sedgeman@gmail.com, @id=1, time=1680411943959}, valueSchema=null, timestamp=1680411943959, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=478, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=162, userEmail=angelo.haggeth@gmail.com, @id=1, time=1680411943963}, valueSchema=null, timestamp=1680411943963, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=479, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=193, userEmail=caresa.tottman@gmail.com, @id=1, time=1680411943966}, valueSchema=null, timestamp=1680411943966, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=480, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=190, userEmail=andriana.coolbear@gmail.com, @id=1, time=1680411943970}, valueSchema=null, timestamp=1680411943970, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=481, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=159, userEmail=kit.henken@gmail.com, @id=1, time=1680411943973}, valueSchema=null, timestamp=1680411943973, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=482, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=222, userEmail=andras.durning@gmail.com, @id=1, time=1680411943977}, valueSchema=null, timestamp=1680411943977, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=483, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=238, userEmail=osborne.janak@gmail.com, @id=1, time=1680411943980}, valueSchema=null, timestamp=1680411943980, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=484, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=216, userEmail=ange.losbie@gmail.com, @id=1, time=1680411943983}, valueSchema=null, timestamp=1680411943983, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=485, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=182, userEmail=christen.kytter@gmail.com, @id=1, time=1680411943986}, valueSchema=null, timestamp=1680411943986, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=486, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=159, userEmail=duff.downey@gmail.com, @id=1, time=1680411954019}, valueSchema=null, timestamp=1680411954019, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=487, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=185, userEmail=rosanne.de_michetti@gmail.com, @id=1, time=1680411954030}, valueSchema=null, timestamp=1680411954030, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=488, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=arnaldo.barrington@gmail.com, @id=1, time=1680411954036}, valueSchema=null, timestamp=1680411954036, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=489, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=243, userEmail=paddie.steers@gmail.com, @id=1, time=1680411954042}, valueSchema=null, timestamp=1680411954042, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=490, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=198, userEmail=saedella.lamacraft@gmail.com, @id=1, time=1680411954047}, valueSchema=null, timestamp=1680411954047, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=491, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=199, userEmail=risa.theseira@gmail.com, @id=1, time=1680411954051}, valueSchema=null, timestamp=1680411954051, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=492, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=161, userEmail=antonio.lumber@gmail.com, @id=1, time=1680411954055}, valueSchema=null, timestamp=1680411954055, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=493, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=192, userEmail=duane.mariet@gmail.com, @id=1, time=1680411954059}, valueSchema=null, timestamp=1680411954059, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=494, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=175, userEmail=charisse.feartherby@gmail.com, @id=1, time=1680411954064}, valueSchema=null, timestamp=1680411954064, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=495, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=250, userEmail=natale.jakoubek@gmail.com, @id=1, time=1680411954068}, valueSchema=null, timestamp=1680411954068, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=496, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=241, userEmail=levin.gregol@gmail.com, @id=1, time=1680411954072}, valueSchema=null, timestamp=1680411954072, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=497, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=200, userEmail=laverne.gabites@gmail.com, @id=1, time=1680411954074}, valueSchema=null, timestamp=1680411954074, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=498, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=206, userEmail=teodoro.baffin@gmail.com, @id=1, time=1680411954077}, valueSchema=null, timestamp=1680411954077, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}, SinkRecord{kafkaOffset=499, timestampType=CreateTime} ConnectRecord{topic='hr-data-collector', kafkaPartition=0, key=null, keySchema=Schema{STRING}, value={heartRate=233, userEmail=maure.gilpin@gmail.com, @id=1, time=1680411954080}, valueSchema=null, timestamp=1680411954080, headers=ConnectHeaders(headers=[ConnectHeader(key=__TypeId__, value=com.sportser.sportserheartratesensordatacollector.dto.HeartRateUserDto, schema=Schema{STRING})])}] (com.mongodb.kafka.connect.sink.MongoSinkTask:243)
com.mongodb.MongoCommandException: Command failed with error 13 (Unauthorized): 'command update requires authentication' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "command update requires authentication", "code": 13, "codeName": "Unauthorized"}
	at com.mongodb.internal.connection.ProtocolHelper.getCommandFailureException(ProtocolHelper.java:198)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:413)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:337)
	at com.mongodb.internal.connection.UsageTrackingInternalConnection.sendAndReceive(UsageTrackingInternalConnection.java:116)
	at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.sendAndReceive(DefaultConnectionPool.java:643)
	at com.mongodb.internal.connection.CommandProtocolImpl.execute(CommandProtocolImpl.java:71)
	at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor.execute(DefaultServer.java:240)
	at com.mongodb.internal.connection.DefaultServerConnection.executeProtocol(DefaultServerConnection.java:226)
	at com.mongodb.internal.connection.DefaultServerConnection.command(DefaultServerConnection.java:126)
	at com.mongodb.internal.connection.DefaultServer$OperationCountTrackingConnection.command(DefaultServer.java:354)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.executeCommand(MixedBulkWriteOperation.java:517)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.executeBulkWriteBatch(MixedBulkWriteOperation.java:379)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$2(MixedBulkWriteOperation.java:300)
	at com.mongodb.internal.operation.OperationHelper.lambda$withSourceAndConnection$2(OperationHelper.java:566)
	at com.mongodb.internal.operation.OperationHelper.withSuppliedResource(OperationHelper.java:591)
	at com.mongodb.internal.operation.OperationHelper.lambda$withSourceAndConnection$3(OperationHelper.java:565)
	at com.mongodb.internal.operation.OperationHelper.withSuppliedResource(OperationHelper.java:591)
	at com.mongodb.internal.operation.OperationHelper.withSourceAndConnection(OperationHelper.java:564)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:272)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:65)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:308)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:85)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:212)
	at com.mongodb.client.internal.MongoCollectionImpl.executeBulkWrite(MongoCollectionImpl.java:448)
	at com.mongodb.client.internal.MongoCollectionImpl.bulkWrite(MongoCollectionImpl.java:428)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.bulkWriteBatch(StartedMongoSinkTask.java:161)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.put(StartedMongoSinkTask.java:117)
	at com.mongodb.kafka.connect.sink.MongoSinkTask.put(MongoSinkTask.java:91)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:583)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:336)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:237)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:206)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:177)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2023-04-02 16:27:05,528] ERROR [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: com.mongodb.MongoCommandException: Command failed with error 13 (Unauthorized): 'command update requires authentication' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "command update requires authentication", "code": 13, "codeName": "Unauthorized"} (org.apache.kafka.connect.runtime.WorkerSinkTask:612)
org.apache.kafka.connect.errors.DataException: com.mongodb.MongoCommandException: Command failed with error 13 (Unauthorized): 'command update requires authentication' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "command update requires authentication", "code": 13, "codeName": "Unauthorized"}
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.handleTolerableWriteException(StartedMongoSinkTask.java:237)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.bulkWriteBatch(StartedMongoSinkTask.java:168)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.put(StartedMongoSinkTask.java:117)
	at com.mongodb.kafka.connect.sink.MongoSinkTask.put(MongoSinkTask.java:91)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:583)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:336)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:237)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:206)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:177)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mongodb.MongoCommandException: Command failed with error 13 (Unauthorized): 'command update requires authentication' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "command update requires authentication", "code": 13, "codeName": "Unauthorized"}
	at com.mongodb.internal.connection.ProtocolHelper.getCommandFailureException(ProtocolHelper.java:198)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:413)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:337)
	at com.mongodb.internal.connection.UsageTrackingInternalConnection.sendAndReceive(UsageTrackingInternalConnection.java:116)
	at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.sendAndReceive(DefaultConnectionPool.java:643)
	at com.mongodb.internal.connection.CommandProtocolImpl.execute(CommandProtocolImpl.java:71)
	at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor.execute(DefaultServer.java:240)
	at com.mongodb.internal.connection.DefaultServerConnection.executeProtocol(DefaultServerConnection.java:226)
	at com.mongodb.internal.connection.DefaultServerConnection.command(DefaultServerConnection.java:126)
	at com.mongodb.internal.connection.DefaultServer$OperationCountTrackingConnection.command(DefaultServer.java:354)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.executeCommand(MixedBulkWriteOperation.java:517)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.executeBulkWriteBatch(MixedBulkWriteOperation.java:379)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$2(MixedBulkWriteOperation.java:300)
	at com.mongodb.internal.operation.OperationHelper.lambda$withSourceAndConnection$2(OperationHelper.java:566)
	at com.mongodb.internal.operation.OperationHelper.withSuppliedResource(OperationHelper.java:591)
	at com.mongodb.internal.operation.OperationHelper.lambda$withSourceAndConnection$3(OperationHelper.java:565)
	at com.mongodb.internal.operation.OperationHelper.withSuppliedResource(OperationHelper.java:591)
	at com.mongodb.internal.operation.OperationHelper.withSourceAndConnection(OperationHelper.java:564)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:272)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:65)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:308)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:85)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:212)
	at com.mongodb.client.internal.MongoCollectionImpl.executeBulkWrite(MongoCollectionImpl.java:448)
	at com.mongodb.client.internal.MongoCollectionImpl.bulkWrite(MongoCollectionImpl.java:428)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.bulkWriteBatch(StartedMongoSinkTask.java:161)
	... 14 more
[2023-04-02 16:27:05,533] ERROR [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:210)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:614)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:336)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:237)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:206)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:177)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.DataException: com.mongodb.MongoCommandException: Command failed with error 13 (Unauthorized): 'command update requires authentication' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "command update requires authentication", "code": 13, "codeName": "Unauthorized"}
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.handleTolerableWriteException(StartedMongoSinkTask.java:237)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.bulkWriteBatch(StartedMongoSinkTask.java:168)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.put(StartedMongoSinkTask.java:117)
	at com.mongodb.kafka.connect.sink.MongoSinkTask.put(MongoSinkTask.java:91)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:583)
	... 11 more
Caused by: com.mongodb.MongoCommandException: Command failed with error 13 (Unauthorized): 'command update requires authentication' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "command update requires authentication", "code": 13, "codeName": "Unauthorized"}
	at com.mongodb.internal.connection.ProtocolHelper.getCommandFailureException(ProtocolHelper.java:198)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:413)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:337)
	at com.mongodb.internal.connection.UsageTrackingInternalConnection.sendAndReceive(UsageTrackingInternalConnection.java:116)
	at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.sendAndReceive(DefaultConnectionPool.java:643)
	at com.mongodb.internal.connection.CommandProtocolImpl.execute(CommandProtocolImpl.java:71)
	at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor.execute(DefaultServer.java:240)
	at com.mongodb.internal.connection.DefaultServerConnection.executeProtocol(DefaultServerConnection.java:226)
	at com.mongodb.internal.connection.DefaultServerConnection.command(DefaultServerConnection.java:126)
	at com.mongodb.internal.connection.DefaultServer$OperationCountTrackingConnection.command(DefaultServer.java:354)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.executeCommand(MixedBulkWriteOperation.java:517)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.executeBulkWriteBatch(MixedBulkWriteOperation.java:379)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$2(MixedBulkWriteOperation.java:300)
	at com.mongodb.internal.operation.OperationHelper.lambda$withSourceAndConnection$2(OperationHelper.java:566)
	at com.mongodb.internal.operation.OperationHelper.withSuppliedResource(OperationHelper.java:591)
	at com.mongodb.internal.operation.OperationHelper.lambda$withSourceAndConnection$3(OperationHelper.java:565)
	at com.mongodb.internal.operation.OperationHelper.withSuppliedResource(OperationHelper.java:591)
	at com.mongodb.internal.operation.OperationHelper.withSourceAndConnection(OperationHelper.java:564)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:272)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:65)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:308)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:85)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:212)
	at com.mongodb.client.internal.MongoCollectionImpl.executeBulkWrite(MongoCollectionImpl.java:448)
	at com.mongodb.client.internal.MongoCollectionImpl.bulkWrite(MongoCollectionImpl.java:428)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.bulkWriteBatch(StartedMongoSinkTask.java:161)
	... 14 more
[2023-04-02 16:27:05,534] INFO [mongodb-sink-connector|task-0] Stopping MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:116)
[2023-04-02 16:27:05,546] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Revoke previously assigned partitions emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:336)
[2023-04-02 16:27:05,547] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Member connector-consumer-mongodb-sink-connector-0-46f9d6cf-3efa-4315-aff0-305f1eeefbc5 sending LeaveGroup request to coordinator m1-yohan:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1123)
[2023-04-02 16:27:05,549] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1015)
[2023-04-02 16:27:05,549] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:27:05,576] INFO [mongodb-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:27:05,577] INFO [mongodb-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:27:05,577] INFO [mongodb-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:27:05,588] INFO [mongodb-sink-connector|task-0] App info kafka.consumer for connector-consumer-mongodb-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:28:08,873] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2023-04-02 16:28:08,900] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:317)
[2023-04-02 16:28:08,924] INFO Stopped http_8083@741b3bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-04-02 16:28:08,926] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-04-02 16:28:08,936] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:334)
[2023-04-02 16:28:08,936] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:106)
[2023-04-02 16:28:08,938] INFO [mongodb-sink-connector|task-0] Stopping task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:998)
[2023-04-02 16:28:08,951] INFO [mongodb-sink-connector|worker] Stopping connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:404)
[2023-04-02 16:28:08,952] INFO [mongodb-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:254)
[2023-04-02 16:28:08,952] INFO [mongodb-sink-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:274)
[2023-04-02 16:28:08,960] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:219)
[2023-04-02 16:28:08,968] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2023-04-02 16:28:08,969] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:28:08,970] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:28:08,970] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:28:08,972] INFO App info kafka.connect for 192.168.1.245:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:28:08,972] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:240)
[2023-04-02 16:28:08,976] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:124)
[2023-04-02 16:28:08,976] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2023-04-02 16:29:36,715] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:29:36,731] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:29:36,737] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2023-04-02 16:29:39,062] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-04-02 16:29:39,063] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,064] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,064] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,065] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,066] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,066] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,066] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,066] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,067] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,068] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,068] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,068] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,068] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,069] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,070] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,071] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,071] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,071] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,071] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:29:39,074] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,074] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,074] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,074] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,076] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,076] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,076] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,077] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,078] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,078] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,078] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,079] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,080] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,081] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,084] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,087] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,087] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,087] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,088] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,088] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,088] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,088] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,088] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,089] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,089] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:29:39,089] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,089] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,089] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:29:39,124] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2023-04-02 16:29:39,125] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:379)
[2023-04-02 16:29:39,125] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:325)
[2023-04-02 16:29:39,128] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2023-04-02 16:29:39,220] WARN These configurations '[offset.flush.interval.ms, key.converter.schemas.enable, offset.storage.file.filename, value.converter.schemas.enable, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:385)
[2023-04-02 16:29:39,221] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:29:39,221] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:29:39,221] INFO Kafka startTimeMs: 1680445779220 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:29:39,556] INFO Kafka cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.connect.runtime.WorkerConfig:342)
[2023-04-02 16:29:39,562] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:29:39,567] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:29:39,567] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:29:39,567] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:29:39,591] INFO Logging initialized @3558ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-04-02 16:29:39,672] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2023-04-02 16:29:39,672] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2023-04-02 16:29:39,724] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_292-b10 (org.eclipse.jetty.server.Server:375)
[2023-04-02 16:29:39,754] INFO Started http_8083@2ed3b1f5{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-04-02 16:29:39,755] INFO Started @3724ms (org.eclipse.jetty.server.Server:415)
[2023-04-02 16:29:39,775] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:29:39,776] INFO REST server listening at http://192.168.1.245:8083/, advertising URL http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2023-04-02 16:29:39,776] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:29:39,776] INFO REST admin endpoints at http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:213)
[2023-04-02 16:29:39,777] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:29:39,779] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-04-02 16:29:39,787] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:29:39,788] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:29:39,788] INFO Kafka startTimeMs: 1680445779787 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:29:39,867] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:29:39,869] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:29:39,874] INFO Kafka Connect standalone worker initialization took 3156ms (org.apache.kafka.connect.cli.ConnectStandalone:103)
[2023-04-02 16:29:39,874] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2023-04-02 16:29:39,874] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2023-04-02 16:29:39,875] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:202)
[2023-04-02 16:29:39,875] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2023-04-02 16:29:39,877] INFO Worker started (org.apache.kafka.connect.runtime.Worker:212)
[2023-04-02 16:29:39,877] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2023-04-02 16:29:39,877] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:217)
[2023-04-02 16:29:39,926] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:236)
[2023-04-02 16:29:39,963] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-04-02 16:29:39,963] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-04-02 16:29:39,965] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2023-04-02 16:29:40,637] INFO Started o.e.j.s.ServletContextHandler@5eefa415{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-04-02 16:29:40,638] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:309)
[2023-04-02 16:29:40,638] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2023-04-02 16:29:40,714] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:29:40,723] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:29:40,725] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:29:40,738] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:29:40,741] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:29:40,745] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:29:40,847] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@90cf7bd]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@6541eb77]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:29:40,881] INFO Opened connection [connectionId{localValue:2, serverValue:749}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:29:40,881] INFO Opened connection [connectionId{localValue:1, serverValue:750}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:29:40,883] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=54887291} (org.mongodb.driver.cluster:71)
[2023-04-02 16:29:40,973] INFO Cluster description not yet available. Waiting for 30000 ms before timing out (org.mongodb.driver.cluster:71)
[2023-04-02 16:29:41,490] INFO Opened connection [connectionId{localValue:4, serverValue:752}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:29:41,491] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=10720708} (org.mongodb.driver.cluster:71)
[2023-04-02 16:29:41,521] INFO Cluster description not yet available. Waiting for 30000 ms before timing out (org.mongodb.driver.cluster:71)
[2023-04-02 16:29:42,054] INFO Opened connection [connectionId{localValue:6, serverValue:754}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:29:42,057] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16563916} (org.mongodb.driver.cluster:71)
[2023-04-02 16:29:42,115] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-04-02 16:29:42,130] ERROR Failed to create job for ../config/mongodb-sink.properties (org.apache.kafka.connect.cli.ConnectStandalone:111)
[2023-04-02 16:29:42,130] ERROR Stopping after connector error (org.apache.kafka.connect.cli.ConnectStandalone:121)
java.util.concurrent.ExecutionException: org.apache.kafka.connect.runtime.rest.errors.BadRequestException: Connector configuration is invalid and contains the following 3 error(s):
Invalid user permissions authentication failed. Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}
Invalid user permissions authentication failed. Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}
Invalid user permissions authentication failed. Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}
You can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`
	at org.apache.kafka.connect.util.ConvertingFutureCallback.result(ConvertingFutureCallback.java:115)
	at org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:99)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:118)
Caused by: org.apache.kafka.connect.runtime.rest.errors.BadRequestException: Connector configuration is invalid and contains the following 3 error(s):
Invalid user permissions authentication failed. Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}
Invalid user permissions authentication failed. Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}
Invalid user permissions authentication failed. Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='toto', source='admin', password=<hidden>, mechanismProperties=<hidden>}
You can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`
	at org.apache.kafka.connect.runtime.AbstractHerder.maybeAddConfigErrors(AbstractHerder.java:741)
	at org.apache.kafka.connect.runtime.standalone.StandaloneHerder.putConnectorConfig(StandaloneHerder.java:206)
	at org.apache.kafka.connect.runtime.standalone.StandaloneHerder.lambda$null$0(StandaloneHerder.java:192)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2023-04-02 16:29:42,133] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2023-04-02 16:29:42,133] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:317)
[2023-04-02 16:29:42,139] INFO Stopped http_8083@2ed3b1f5{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-04-02 16:29:42,140] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-04-02 16:29:42,143] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:334)
[2023-04-02 16:29:42,144] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:106)
[2023-04-02 16:29:42,144] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:219)
[2023-04-02 16:29:42,145] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2023-04-02 16:29:42,145] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:29:42,145] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:29:42,146] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:29:42,148] INFO App info kafka.connect for 192.168.1.245:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:29:42,148] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:240)
[2023-04-02 16:29:42,149] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:124)
[2023-04-02 16:29:42,150] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2023-04-02 16:31:47,645] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-04-02 16:31:47,657] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../logs, -Dlog4j.configuration=file:./../config/connect-log4j.properties
	jvm.spec = AdoptOpenJDK, OpenJDK 64-Bit Server VM, 1.8.0_292, 25.292-b10
	jvm.classpath = /Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/activation-1.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/argparse4j-0.7.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-cli-1.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-json-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-mirror-client-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-runtime-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/connect-transforms-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-api-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-core-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-databind-2.13.4.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jackson-module-scala_2.13-2.13.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javassist-3.27.0-GA.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-client-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-common-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-hk2-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jersey-server-2.34.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jline-3.21.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/jose4j-0.7.9.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-clients-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-group-coordinator-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-log4j-appender-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-metadata-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-raft-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-server-common-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-shell-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-storage-api-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-examples-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-scala_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka-tools-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/kafka_2.13-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/lz4-java-1.8.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/maven-artifact-3.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/mongo-kafka-connect-1.10.0-confluent.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-buffer-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-codec-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-handler-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-resolver-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/paranamer-2.8.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/plexus-utils-3.3.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reflections-0.9.12.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/reload4j-1.2.19.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/rocksdbjni-7.1.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-library-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/scala-reflect-2.13.10.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/snappy-java-1.1.8.4.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/swagger-annotations-2.2.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/trogdor-3.4.0.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zookeeper-jute-3.6.3.jar:/Users/yohan/Downloads/kafka_2.13-3.4.0/bin/../libs/zstd-jni-1.5.2-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-04-02 16:31:47,662] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2023-04-02 16:31:49,674] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-04-02 16:31:49,675] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,676] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,676] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,677] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,678] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,678] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,678] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,679] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,680] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,680] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,680] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,680] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,680] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,681] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,682] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,683] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,683] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:228)
[2023-04-02 16:31:49,684] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,684] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,684] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,685] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,685] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,685] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,685] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,685] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,686] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,686] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,686] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,686] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,686] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,686] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,687] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,687] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,687] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,687] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,687] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,688] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,688] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,688] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,688] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,689] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,689] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,689] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,689] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,691] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,692] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,692] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,692] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,692] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,692] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,692] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,692] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,693] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,693] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,693] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:471)
[2023-04-02 16:31:49,693] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,693] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,693] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:474)
[2023-04-02 16:31:49,721] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2023-04-02 16:31:49,722] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:379)
[2023-04-02 16:31:49,723] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:325)
[2023-04-02 16:31:49,725] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2023-04-02 16:31:49,806] WARN These configurations '[offset.flush.interval.ms, key.converter.schemas.enable, offset.storage.file.filename, value.converter.schemas.enable, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:385)
[2023-04-02 16:31:49,807] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:31:49,807] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:31:49,807] INFO Kafka startTimeMs: 1680445909806 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:31:50,249] INFO Kafka cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.connect.runtime.WorkerConfig:342)
[2023-04-02 16:31:50,255] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:31:50,267] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:31:50,268] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:31:50,268] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:31:50,286] INFO Logging initialized @3130ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-04-02 16:31:50,390] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2023-04-02 16:31:50,390] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2023-04-02 16:31:50,439] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_292-b10 (org.eclipse.jetty.server.Server:375)
[2023-04-02 16:31:50,473] INFO Started http_8083@741b3bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-04-02 16:31:50,473] INFO Started @3318ms (org.eclipse.jetty.server.Server:415)
[2023-04-02 16:31:50,492] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:31:50,492] INFO REST server listening at http://192.168.1.245:8083/, advertising URL http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2023-04-02 16:31:50,492] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:31:50,492] INFO REST admin endpoints at http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:213)
[2023-04-02 16:31:50,492] INFO Advertised URI: http://192.168.1.245:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:363)
[2023-04-02 16:31:50,494] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-04-02 16:31:50,503] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:31:50,503] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:31:50,503] INFO Kafka startTimeMs: 1680445910502 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:31:50,579] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:31:50,580] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:31:50,585] INFO Kafka Connect standalone worker initialization took 2938ms (org.apache.kafka.connect.cli.ConnectStandalone:103)
[2023-04-02 16:31:50,586] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2023-04-02 16:31:50,586] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2023-04-02 16:31:50,586] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:202)
[2023-04-02 16:31:50,586] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2023-04-02 16:31:50,589] INFO Worker started (org.apache.kafka.connect.runtime.Worker:212)
[2023-04-02 16:31:50,589] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2023-04-02 16:31:50,589] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:217)
[2023-04-02 16:31:50,636] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:236)
[2023-04-02 16:31:50,668] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-04-02 16:31:50,668] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-04-02 16:31:50,669] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2023-04-02 16:31:51,354] INFO Started o.e.j.s.ServletContextHandler@5eefa415{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-04-02 16:31:51,355] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:309)
[2023-04-02 16:31:51,355] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2023-04-02 16:31:51,422] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,427] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,429] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,437] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,438] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,440] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,520] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='toto', source='sportser', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7b1ce5a5]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@78e1ffae]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:31:51,547] INFO Opened connection [connectionId{localValue:1, serverValue:756}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:31:51,547] INFO Opened connection [connectionId{localValue:2, serverValue:757}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:31:51,548] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=27824708} (org.mongodb.driver.cluster:71)
[2023-04-02 16:31:51,779] INFO Opened connection [connectionId{localValue:3, serverValue:758}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:31:51,838] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-04-02 16:31:51,869] INFO [mongodb-sink-connector|worker] Creating connector mongodb-sink-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:293)
[2023-04-02 16:31:51,873] INFO [mongodb-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:31:51,873] INFO [mongodb-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:31:51,881] INFO [mongodb-sink-connector|worker] Instantiated connector mongodb-sink-connector with version 1.10.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:315)
[2023-04-02 16:31:51,881] INFO [mongodb-sink-connector|worker] Finished creating connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:336)
[2023-04-02 16:31:51,884] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:31:51,885] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:31:51,888] INFO [mongodb-sink-connector|task-0] Creating task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:596)
[2023-04-02 16:31:51,897] INFO [mongodb-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2023-04-02 16:31:51,897] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:31:51,898] INFO [mongodb-sink-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2023-04-02 16:31:51,899] INFO [mongodb-sink-connector|task-0] Instantiated task mongodb-sink-connector-0 with version 1.10.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:610)
[2023-04-02 16:31:51,901] INFO [mongodb-sink-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:376)
[2023-04-02 16:31:51,902] INFO [mongodb-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-04-02 16:31:51,902] INFO [mongodb-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongodb-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:625)
[2023-04-02 16:31:51,902] INFO [mongodb-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:631)
[2023-04-02 16:31:51,902] INFO [mongodb-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:636)
[2023-04-02 16:31:51,908] INFO [mongodb-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1257)
[2023-04-02 16:31:51,910] INFO [mongodb-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-04-02 16:31:51,910] INFO [mongodb-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink-connector
	predicates = []
	tasks.max = 1
	topics = [emergency-data-collector, hr-data-collector, notification-channel]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-04-02 16:31:51,918] INFO [mongodb-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongodb-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongodb-sink-connector
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2023-04-02 16:31:51,957] WARN [mongodb-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:385)
[2023-04-02 16:31:51,957] INFO [mongodb-sink-connector|task-0] Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-04-02 16:31:51,957] INFO [mongodb-sink-connector|task-0] Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-04-02 16:31:51,957] INFO [mongodb-sink-connector|task-0] Kafka startTimeMs: 1680445911957 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-04-02 16:31:51,967] INFO Created connector mongodb-sink-connector (org.apache.kafka.connect.cli.ConnectStandalone:113)
[2023-04-02 16:31:51,968] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Subscribed to topic(s): emergency-data-collector, hr-data-collector, notification-channel (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2023-04-02 16:31:51,968] INFO [mongodb-sink-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:65)
[2023-04-02 16:31:51,974] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = emergency-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,975] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = hr-data-collector
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,977] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = sportser
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = notification-channel
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:376)
[2023-04-02 16:31:51,983] INFO [mongodb-sink-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.10.0"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/AdoptOpenJDK/1.8.0_292-b10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='toto', source='sportser', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7b1ce5a5]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2023-04-02 16:31:51,986] INFO [mongodb-sink-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:130)
[2023-04-02 16:31:51,992] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:5, serverValue:760}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:31:51,995] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:4, serverValue:759}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:31:51,996] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=11456292} (org.mongodb.driver.cluster:71)
[2023-04-02 16:31:52,003] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:316)
[2023-04-02 16:31:52,005] INFO [mongodb-sink-connector|task-0] WorkerSinkTask{id=mongodb-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:201)
[2023-04-02 16:31:52,042] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition notification-channel-0 to 0 since the associated topicId changed from null to aNC6h-jiR52lEVqVKTD2Ug (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:31:52,043] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition emergency-data-collector-0 to 0 since the associated topicId changed from null to Yg93KKfEREu7IYKtwwu5Vg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:31:52,043] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting the last seen epoch of partition hr-data-collector-0 to 0 since the associated topicId changed from null to Un46eKRYRXK2oaNAf1sTKg (org.apache.kafka.clients.Metadata:402)
[2023-04-02 16:31:52,046] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Cluster ID: YrSa-kk3RIekbfVyN6fSRQ (org.apache.kafka.clients.Metadata:287)
[2023-04-02 16:31:52,047] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator m1-yohan:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:896)
[2023-04-02 16:31:52,051] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:31:52,100] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-1b7cb62d-eee0-45b9-bcbf-da2662e8ced0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:31:52,103] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:31:52,103] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-04-02 16:31:52,132] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-mongodb-sink-connector-0-1b7cb62d-eee0-45b9-bcbf-da2662e8ced0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:627)
[2023-04-02 16:31:52,138] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Finished assignment for group at generation 3: {connector-consumer-mongodb-sink-connector-0-1b7cb62d-eee0-45b9-bcbf-da2662e8ced0=Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:710)
[2023-04-02 16:31:52,158] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-mongodb-sink-connector-0-1b7cb62d-eee0-45b9-bcbf-da2662e8ced0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:802)
[2023-04-02 16:31:52,160] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Notifying assignor about the new Assignment(partitions=[notification-channel-0, emergency-data-collector-0, hr-data-collector-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:305)
[2023-04-02 16:31:52,166] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Adding newly assigned partitions: emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:317)
[2023-04-02 16:31:52,189] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:31:52,189] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition emergency-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:31:52,190] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition hr-data-collector-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1543)
[2023-04-02 16:31:52,222] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition notification-channel-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:31:52,226] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition emergency-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:31:52,227] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition hr-data-collector-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[m1-yohan:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-04-02 16:31:52,478] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:6, serverValue:761}] to localhost:27017 (org.mongodb.driver.connection:71)
[2023-04-02 16:35:12,141] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2023-04-02 16:35:12,165] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:317)
[2023-04-02 16:35:12,210] INFO Stopped http_8083@741b3bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-04-02 16:35:12,210] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-04-02 16:35:12,216] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:334)
[2023-04-02 16:35:12,217] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:106)
[2023-04-02 16:35:12,218] INFO [mongodb-sink-connector|task-0] Stopping task mongodb-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:998)
[2023-04-02 16:35:12,221] INFO [mongodb-sink-connector|task-0] Stopping MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:116)
[2023-04-02 16:35:12,251] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Revoke previously assigned partitions emergency-data-collector-0, hr-data-collector-0, notification-channel-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:336)
[2023-04-02 16:35:12,254] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Member connector-consumer-mongodb-sink-connector-0-1b7cb62d-eee0-45b9-bcbf-da2662e8ced0 sending LeaveGroup request to coordinator m1-yohan:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1123)
[2023-04-02 16:35:12,257] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1015)
[2023-04-02 16:35:12,257] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1062)
[2023-04-02 16:35:12,337] INFO [mongodb-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:35:12,337] INFO [mongodb-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:35:12,337] INFO [mongodb-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:35:12,347] INFO [mongodb-sink-connector|task-0] App info kafka.consumer for connector-consumer-mongodb-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:35:12,369] INFO [mongodb-sink-connector|worker] Stopping connector mongodb-sink-connector (org.apache.kafka.connect.runtime.Worker:404)
[2023-04-02 16:35:12,370] INFO [mongodb-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:254)
[2023-04-02 16:35:12,370] INFO [mongodb-sink-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:274)
[2023-04-02 16:35:12,372] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:219)
[2023-04-02 16:35:12,381] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2023-04-02 16:35:12,381] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-04-02 16:35:12,382] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-04-02 16:35:12,382] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-04-02 16:35:12,383] INFO App info kafka.connect for 192.168.1.245:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-04-02 16:35:12,384] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:240)
[2023-04-02 16:35:12,390] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:124)
[2023-04-02 16:35:12,390] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
